2023-12-13 19:25:52,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-13 19:25:52,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-13 19:25:52,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-13 19:25:52,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-13 19:26:15,813:INFO:PyCaret ClassificationExperiment
2023-12-13 19:26:15,813:INFO:Logging name: clf-default-name
2023-12-13 19:26:15,821:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-12-13 19:26:15,821:INFO:version 3.2.0
2023-12-13 19:26:15,821:INFO:Initializing setup()
2023-12-13 19:26:15,821:INFO:self.USI: a928
2023-12-13 19:26:15,821:INFO:self._variable_keys: {'exp_id', 'fold_generator', 'X', 'gpu_n_jobs_param', 'memory', 'y', '_available_plots', 'html_param', 'seed', 'fix_imbalance', 'exp_name_log', 'X_test', 'log_plots_param', 'pipeline', '_ml_usecase', 'X_train', 'fold_groups_param', 'target_param', 'idx', 'gpu_param', 'fold_shuffle_param', 'data', 'is_multiclass', 'y_test', 'y_train', 'USI', 'n_jobs_param', 'logging_param'}
2023-12-13 19:26:15,821:INFO:Checking environment
2023-12-13 19:26:15,821:INFO:python_version: 3.10.6
2023-12-13 19:26:15,821:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-12-13 19:26:15,821:INFO:machine: AMD64
2023-12-13 19:26:15,821:INFO:platform: Windows-10-10.0.19045-SP0
2023-12-13 19:26:15,821:INFO:Memory: svmem(total=21264392192, available=11425034240, percent=46.3, used=9839357952, free=11425034240)
2023-12-13 19:26:15,821:INFO:Physical Core: 4
2023-12-13 19:26:15,821:INFO:Logical Core: 8
2023-12-13 19:26:15,821:INFO:Checking libraries
2023-12-13 19:26:15,821:INFO:System:
2023-12-13 19:26:15,821:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-12-13 19:26:15,821:INFO:executable: c:\Users\lenovo\AppData\Local\Programs\Python\Python310\python.exe
2023-12-13 19:26:15,821:INFO:   machine: Windows-10-10.0.19045-SP0
2023-12-13 19:26:15,821:INFO:PyCaret required dependencies:
2023-12-13 19:26:15,905:INFO:                 pip: 23.3.1
2023-12-13 19:26:15,905:INFO:          setuptools: 63.2.0
2023-12-13 19:26:15,905:INFO:             pycaret: 3.2.0
2023-12-13 19:26:15,905:INFO:             IPython: 8.4.0
2023-12-13 19:26:15,905:INFO:          ipywidgets: 8.1.1
2023-12-13 19:26:15,905:INFO:                tqdm: 4.65.0
2023-12-13 19:26:15,905:INFO:               numpy: 1.24.4
2023-12-13 19:26:15,905:INFO:              pandas: 1.4.3
2023-12-13 19:26:15,905:INFO:              jinja2: 3.1.2
2023-12-13 19:26:15,905:INFO:               scipy: 1.10.1
2023-12-13 19:26:15,905:INFO:              joblib: 1.2.0
2023-12-13 19:26:15,905:INFO:             sklearn: 1.0.2
2023-12-13 19:26:15,905:INFO:                pyod: 1.1.2
2023-12-13 19:26:15,905:INFO:            imblearn: 0.10.1
2023-12-13 19:26:15,905:INFO:   category_encoders: 2.6.3
2023-12-13 19:26:15,905:INFO:            lightgbm: 4.1.0
2023-12-13 19:26:15,905:INFO:               numba: 0.58.1
2023-12-13 19:26:15,905:INFO:            requests: 2.28.1
2023-12-13 19:26:15,905:INFO:          matplotlib: 3.8.2
2023-12-13 19:26:15,905:INFO:          scikitplot: 0.3.7
2023-12-13 19:26:15,905:INFO:         yellowbrick: 1.5
2023-12-13 19:26:15,905:INFO:              plotly: 5.10.0
2023-12-13 19:26:15,905:INFO:    plotly-resampler: Not installed
2023-12-13 19:26:15,905:INFO:             kaleido: 0.2.1
2023-12-13 19:26:15,905:INFO:           schemdraw: 0.15
2023-12-13 19:26:15,905:INFO:         statsmodels: 0.14.0
2023-12-13 19:26:15,905:INFO:              sktime: 0.21.1
2023-12-13 19:26:15,905:INFO:               tbats: 1.1.3
2023-12-13 19:26:15,905:INFO:            pmdarima: 2.0.4
2023-12-13 19:26:15,905:INFO:              psutil: 5.9.1
2023-12-13 19:26:15,905:INFO:          markupsafe: 2.1.1
2023-12-13 19:26:15,905:INFO:             pickle5: Not installed
2023-12-13 19:26:15,905:INFO:         cloudpickle: 3.0.0
2023-12-13 19:26:15,905:INFO:         deprecation: 2.1.0
2023-12-13 19:26:15,905:INFO:              xxhash: 3.4.1
2023-12-13 19:26:15,905:INFO:           wurlitzer: Not installed
2023-12-13 19:26:15,905:INFO:PyCaret optional dependencies:
2023-12-13 19:26:15,914:INFO:                shap: Not installed
2023-12-13 19:26:15,914:INFO:           interpret: Not installed
2023-12-13 19:26:15,914:INFO:                umap: Not installed
2023-12-13 19:26:15,914:INFO:     ydata_profiling: Not installed
2023-12-13 19:26:15,914:INFO:  explainerdashboard: Not installed
2023-12-13 19:26:15,914:INFO:             autoviz: Not installed
2023-12-13 19:26:15,914:INFO:           fairlearn: Not installed
2023-12-13 19:26:15,914:INFO:          deepchecks: Not installed
2023-12-13 19:26:15,914:INFO:             xgboost: 1.7.3
2023-12-13 19:26:15,914:INFO:            catboost: Not installed
2023-12-13 19:26:15,914:INFO:              kmodes: Not installed
2023-12-13 19:26:15,914:INFO:             mlxtend: Not installed
2023-12-13 19:26:15,914:INFO:       statsforecast: Not installed
2023-12-13 19:26:15,914:INFO:        tune_sklearn: Not installed
2023-12-13 19:26:15,914:INFO:                 ray: Not installed
2023-12-13 19:26:15,914:INFO:            hyperopt: Not installed
2023-12-13 19:26:15,914:INFO:              optuna: Not installed
2023-12-13 19:26:15,914:INFO:               skopt: Not installed
2023-12-13 19:26:15,914:INFO:              mlflow: Not installed
2023-12-13 19:26:15,914:INFO:              gradio: Not installed
2023-12-13 19:26:15,914:INFO:             fastapi: Not installed
2023-12-13 19:26:15,914:INFO:             uvicorn: Not installed
2023-12-13 19:26:15,914:INFO:              m2cgen: Not installed
2023-12-13 19:26:15,914:INFO:           evidently: Not installed
2023-12-13 19:26:15,914:INFO:               fugue: Not installed
2023-12-13 19:26:15,914:INFO:           streamlit: 1.27.2
2023-12-13 19:26:15,914:INFO:             prophet: Not installed
2023-12-13 19:26:15,914:INFO:None
2023-12-13 19:26:15,914:INFO:Set up data.
2023-12-13 19:26:35,045:INFO:PyCaret ClassificationExperiment
2023-12-13 19:26:35,045:INFO:Logging name: clf-default-name
2023-12-13 19:26:35,045:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-12-13 19:26:35,045:INFO:version 3.2.0
2023-12-13 19:26:35,045:INFO:Initializing setup()
2023-12-13 19:26:35,045:INFO:self.USI: d604
2023-12-13 19:26:35,045:INFO:self._variable_keys: {'exp_id', 'fold_generator', 'X', 'gpu_n_jobs_param', 'memory', 'y', '_available_plots', 'html_param', 'seed', 'fix_imbalance', 'exp_name_log', 'X_test', 'log_plots_param', 'pipeline', '_ml_usecase', 'X_train', 'fold_groups_param', 'target_param', 'idx', 'gpu_param', 'fold_shuffle_param', 'data', 'is_multiclass', 'y_test', 'y_train', 'USI', 'n_jobs_param', 'logging_param'}
2023-12-13 19:26:35,045:INFO:Checking environment
2023-12-13 19:26:35,045:INFO:python_version: 3.10.6
2023-12-13 19:26:35,045:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-12-13 19:26:35,045:INFO:machine: AMD64
2023-12-13 19:26:35,045:INFO:platform: Windows-10-10.0.19045-SP0
2023-12-13 19:26:35,045:INFO:Memory: svmem(total=21264392192, available=11361136640, percent=46.6, used=9903255552, free=11361136640)
2023-12-13 19:26:35,045:INFO:Physical Core: 4
2023-12-13 19:26:35,045:INFO:Logical Core: 8
2023-12-13 19:26:35,045:INFO:Checking libraries
2023-12-13 19:26:35,045:INFO:System:
2023-12-13 19:26:35,045:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-12-13 19:26:35,045:INFO:executable: c:\Users\lenovo\AppData\Local\Programs\Python\Python310\python.exe
2023-12-13 19:26:35,045:INFO:   machine: Windows-10-10.0.19045-SP0
2023-12-13 19:26:35,045:INFO:PyCaret required dependencies:
2023-12-13 19:26:35,045:INFO:                 pip: 23.3.1
2023-12-13 19:26:35,045:INFO:          setuptools: 63.2.0
2023-12-13 19:26:35,045:INFO:             pycaret: 3.2.0
2023-12-13 19:26:35,045:INFO:             IPython: 8.4.0
2023-12-13 19:26:35,045:INFO:          ipywidgets: 8.1.1
2023-12-13 19:26:35,045:INFO:                tqdm: 4.65.0
2023-12-13 19:26:35,045:INFO:               numpy: 1.24.4
2023-12-13 19:26:35,045:INFO:              pandas: 1.4.3
2023-12-13 19:26:35,045:INFO:              jinja2: 3.1.2
2023-12-13 19:26:35,045:INFO:               scipy: 1.10.1
2023-12-13 19:26:35,045:INFO:              joblib: 1.2.0
2023-12-13 19:26:35,045:INFO:             sklearn: 1.0.2
2023-12-13 19:26:35,045:INFO:                pyod: 1.1.2
2023-12-13 19:26:35,045:INFO:            imblearn: 0.10.1
2023-12-13 19:26:35,045:INFO:   category_encoders: 2.6.3
2023-12-13 19:26:35,045:INFO:            lightgbm: 4.1.0
2023-12-13 19:26:35,045:INFO:               numba: 0.58.1
2023-12-13 19:26:35,045:INFO:            requests: 2.28.1
2023-12-13 19:26:35,045:INFO:          matplotlib: 3.8.2
2023-12-13 19:26:35,045:INFO:          scikitplot: 0.3.7
2023-12-13 19:26:35,045:INFO:         yellowbrick: 1.5
2023-12-13 19:26:35,045:INFO:              plotly: 5.10.0
2023-12-13 19:26:35,045:INFO:    plotly-resampler: Not installed
2023-12-13 19:26:35,045:INFO:             kaleido: 0.2.1
2023-12-13 19:26:35,045:INFO:           schemdraw: 0.15
2023-12-13 19:26:35,045:INFO:         statsmodels: 0.14.0
2023-12-13 19:26:35,045:INFO:              sktime: 0.21.1
2023-12-13 19:26:35,045:INFO:               tbats: 1.1.3
2023-12-13 19:26:35,045:INFO:            pmdarima: 2.0.4
2023-12-13 19:26:35,045:INFO:              psutil: 5.9.1
2023-12-13 19:26:35,045:INFO:          markupsafe: 2.1.1
2023-12-13 19:26:35,045:INFO:             pickle5: Not installed
2023-12-13 19:26:35,045:INFO:         cloudpickle: 3.0.0
2023-12-13 19:26:35,045:INFO:         deprecation: 2.1.0
2023-12-13 19:26:35,045:INFO:              xxhash: 3.4.1
2023-12-13 19:26:35,045:INFO:           wurlitzer: Not installed
2023-12-13 19:26:35,045:INFO:PyCaret optional dependencies:
2023-12-13 19:26:35,045:INFO:                shap: Not installed
2023-12-13 19:26:35,045:INFO:           interpret: Not installed
2023-12-13 19:26:35,045:INFO:                umap: Not installed
2023-12-13 19:26:35,045:INFO:     ydata_profiling: Not installed
2023-12-13 19:26:35,045:INFO:  explainerdashboard: Not installed
2023-12-13 19:26:35,045:INFO:             autoviz: Not installed
2023-12-13 19:26:35,045:INFO:           fairlearn: Not installed
2023-12-13 19:26:35,045:INFO:          deepchecks: Not installed
2023-12-13 19:26:35,045:INFO:             xgboost: 1.7.3
2023-12-13 19:26:35,045:INFO:            catboost: Not installed
2023-12-13 19:26:35,045:INFO:              kmodes: Not installed
2023-12-13 19:26:35,045:INFO:             mlxtend: Not installed
2023-12-13 19:26:35,045:INFO:       statsforecast: Not installed
2023-12-13 19:26:35,045:INFO:        tune_sklearn: Not installed
2023-12-13 19:26:35,045:INFO:                 ray: Not installed
2023-12-13 19:26:35,045:INFO:            hyperopt: Not installed
2023-12-13 19:26:35,045:INFO:              optuna: Not installed
2023-12-13 19:26:35,045:INFO:               skopt: Not installed
2023-12-13 19:26:35,045:INFO:              mlflow: Not installed
2023-12-13 19:26:35,045:INFO:              gradio: Not installed
2023-12-13 19:26:35,045:INFO:             fastapi: Not installed
2023-12-13 19:26:35,045:INFO:             uvicorn: Not installed
2023-12-13 19:26:35,045:INFO:              m2cgen: Not installed
2023-12-13 19:26:35,045:INFO:           evidently: Not installed
2023-12-13 19:26:35,045:INFO:               fugue: Not installed
2023-12-13 19:26:35,045:INFO:           streamlit: 1.27.2
2023-12-13 19:26:35,045:INFO:             prophet: Not installed
2023-12-13 19:26:35,045:INFO:None
2023-12-13 19:26:35,045:INFO:Set up data.
2023-12-13 19:26:35,053:INFO:Set up folding strategy.
2023-12-13 19:26:35,053:INFO:Set up train/test split.
2023-12-13 19:26:35,063:INFO:Set up index.
2023-12-13 19:26:35,063:INFO:Assigning column types.
2023-12-13 19:26:35,071:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-12-13 19:26:35,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-13 19:26:35,136:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-13 19:26:35,180:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-13 19:26:35,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-13 19:26:35,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-13 19:26:35,347:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-13 19:26:35,380:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-13 19:26:35,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-13 19:26:35,380:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-12-13 19:26:35,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-13 19:26:35,446:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-13 19:26:35,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-13 19:26:35,480:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-13 19:26:35,514:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-13 19:26:35,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-13 19:26:35,514:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-12-13 19:26:35,570:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-13 19:26:35,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-13 19:26:35,646:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-13 19:26:35,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-13 19:26:35,657:INFO:Preparing preprocessing pipeline...
2023-12-13 19:26:35,657:INFO:Set up simple imputation.
2023-12-13 19:26:35,657:INFO:Set up column name cleaning.
2023-12-13 19:26:35,679:INFO:Finished creating preprocessing pipeline.
2023-12-13 19:26:35,687:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Date', 'CarCount', 'BikeCount',
                                             'BusCount', 'TruckCount', 'Total',
                                             'Day', 'Daytime', 'MonthQuarter'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              v...se=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-12-13 19:26:35,687:INFO:Creating final display dataframe.
2023-12-13 19:26:35,746:INFO:Setup _display_container:                     Description              Value
0                    Session id               4195
1                        Target  Traffic Situation
2                   Target type         Multiclass
3           Original data shape         (2976, 10)
4        Transformed data shape         (2976, 10)
5   Transformed train set shape         (2083, 10)
6    Transformed test set shape          (893, 10)
7              Numeric features                  9
8                    Preprocess               True
9               Imputation type             simple
10           Numeric imputation               mean
11       Categorical imputation               mode
12               Fold Generator    StratifiedKFold
13                  Fold Number                 10
14                     CPU Jobs                 -1
15                      Use GPU              False
16               Log Experiment              False
17              Experiment Name   clf-default-name
18                          USI               d604
2023-12-13 19:26:35,837:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-13 19:26:35,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-13 19:26:35,920:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-13 19:26:35,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-13 19:26:35,920:INFO:setup() successfully completed in 0.88s...............
2023-12-13 19:28:51,914:INFO:Initializing create_model()
2023-12-13 19:28:51,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'data':       Date  CarCount  BikeCount  BusCount  TruckCount  Total  \
0        1        97          2        16           7    122   
1        1        22          8        31           8     69   
2        1        31         23        19          12     85   
3        1        49         22        16           5     92   
4        1        32          5         3          21     61   
...    ...       ...        ...       ...         ...    ...   
2971    31       108         20        14          15    157   
2972    31        69         13        13           8    103   
2973    31        64         14        10           6     94   
2974    31        71         14        17          10    112   
2975    31        61          9        18          24    112   

      Traffic Situation  Day  Daytime  MonthQuarter  
0                     1    4        1             1  
1                     1    4        1             1  
2                     1    4        1             1  
3                     1    4        1             1  
4                     1    4        1             1  
...                 ...  ...      ...           ...  
2971                  1    3        4             4  
2972                  0    3        4             4  
2973                  0    3        4             4  
2974                  1    3        4             4  
2975                  2    3        4             4  

[2976 rows x 10 columns], 'method': 'smote'})
2023-12-13 19:28:51,914:INFO:Checking exceptions
2023-12-13 19:28:51,951:INFO:Importing libraries
2023-12-13 19:28:51,951:INFO:Copying training dataset
2023-12-13 19:28:51,951:INFO:Defining folds
2023-12-13 19:28:51,951:INFO:Declaring metric variables
2023-12-13 19:28:51,959:INFO:Importing untrained model
2023-12-13 19:29:00,901:INFO:Initializing create_model()
2023-12-13 19:29:00,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=      Date  CarCount  BikeCount  BusCount  TruckCount  Total  \
0        1        97          2        16           7    122   
1        1        22          8        31           8     69   
2        1        31         23        19          12     85   
3        1        49         22        16           5     92   
4        1        32          5         3          21     61   
...    ...       ...        ...       ...         ...    ...   
2971    31       108         20        14          15    157   
2972    31        69         13        13           8    103   
2973    31        64         14        10           6     94   
2974    31        71         14        17          10    112   
2975    31        61          9        18          24    112   

      Traffic Situation  Day  Daytime  MonthQuarter  
0                     1    4        1             1  
1                     1    4        1             1  
2                     1    4        1             1  
3                     1    4        1             1  
4                     1    4        1             1  
...                 ...  ...      ...           ...  
2971                  1    3        4             4  
2972                  0    3        4             4  
2973                  0    3        4             4  
2974                  1    3        4             4  
2975                  2    3        4             4  

[2976 rows x 10 columns], fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'method': 'smote'})
2023-12-13 19:29:00,901:INFO:Checking exceptions
2023-12-13 19:29:08,045:INFO:Initializing create_model()
2023-12-13 19:29:08,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=      Date  CarCount  BikeCount  BusCount  TruckCount  Total  \
0        1        97          2        16           7    122   
1        1        22          8        31           8     69   
2        1        31         23        19          12     85   
3        1        49         22        16           5     92   
4        1        32          5         3          21     61   
...    ...       ...        ...       ...         ...    ...   
2971    31       108         20        14          15    157   
2972    31        69         13        13           8    103   
2973    31        64         14        10           6     94   
2974    31        71         14        17          10    112   
2975    31        61          9        18          24    112   

      Traffic Situation  Day  Daytime  MonthQuarter  
0                     1    4        1             1  
1                     1    4        1             1  
2                     1    4        1             1  
3                     1    4        1             1  
4                     1    4        1             1  
...                 ...  ...      ...           ...  
2971                  1    3        4             4  
2972                  0    3        4             4  
2973                  0    3        4             4  
2974                  1    3        4             4  
2975                  2    3        4             4  

[2976 rows x 10 columns], fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'method': 'smote'})
2023-12-13 19:29:08,078:INFO:Checking exceptions
2023-12-13 19:29:26,876:INFO:Initializing create_model()
2023-12-13 19:29:26,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'data':       Date  CarCount  BikeCount  BusCount  TruckCount  Total  \
0        1        97          2        16           7    122   
1        1        22          8        31           8     69   
2        1        31         23        19          12     85   
3        1        49         22        16           5     92   
4        1        32          5         3          21     61   
...    ...       ...        ...       ...         ...    ...   
2971    31       108         20        14          15    157   
2972    31        69         13        13           8    103   
2973    31        64         14        10           6     94   
2974    31        71         14        17          10    112   
2975    31        61          9        18          24    112   

      Traffic Situation  Day  Daytime  MonthQuarter  
0                     1    4        1             1  
1                     1    4        1             1  
2                     1    4        1             1  
3                     1    4        1             1  
4                     1    4        1             1  
...                 ...  ...      ...           ...  
2971                  1    3        4             4  
2972                  0    3        4             4  
2973                  0    3        4             4  
2974                  1    3        4             4  
2975                  2    3        4             4  

[2976 rows x 10 columns], 'method': 'smote'})
2023-12-13 19:29:26,876:INFO:Checking exceptions
2023-12-13 19:29:26,910:INFO:Importing libraries
2023-12-13 19:29:26,910:INFO:Copying training dataset
2023-12-13 19:29:26,918:INFO:Defining folds
2023-12-13 19:29:26,918:INFO:Declaring metric variables
2023-12-13 19:29:26,918:INFO:Importing untrained model
2023-12-13 19:30:02,544:INFO:Initializing compare_models()
2023-12-13 19:30:02,544:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-12-13 19:30:02,544:INFO:Checking exceptions
2023-12-13 19:30:02,544:INFO:Preparing display monitor
2023-12-13 19:30:02,592:INFO:Initializing Logistic Regression
2023-12-13 19:30:02,592:INFO:Total runtime is 0.0 minutes
2023-12-13 19:30:02,594:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:02,594:INFO:Initializing create_model()
2023-12-13 19:30:02,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:02,594:INFO:Checking exceptions
2023-12-13 19:30:02,601:INFO:Importing libraries
2023-12-13 19:30:02,601:INFO:Copying training dataset
2023-12-13 19:30:02,601:INFO:Defining folds
2023-12-13 19:30:02,601:INFO:Declaring metric variables
2023-12-13 19:30:02,607:INFO:Importing untrained model
2023-12-13 19:30:02,607:INFO:Logistic Regression Imported successfully
2023-12-13 19:30:02,615:INFO:Starting cross validation
2023-12-13 19:30:02,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:08,195:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,211:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,211:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,227:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,248:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,264:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,359:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,359:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,981:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:08,994:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:30:09,002:INFO:Calculating mean and std
2023-12-13 19:30:09,011:INFO:Creating metrics dataframe
2023-12-13 19:30:09,015:INFO:Uploading results into container
2023-12-13 19:30:09,015:INFO:Uploading model into container now
2023-12-13 19:30:09,017:INFO:_master_model_container: 1
2023-12-13 19:30:09,017:INFO:_display_container: 2
2023-12-13 19:30:09,017:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4195, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-12-13 19:30:09,017:INFO:create_model() successfully completed......................................
2023-12-13 19:30:09,161:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:09,161:INFO:Creating metrics dataframe
2023-12-13 19:30:09,164:INFO:Initializing K Neighbors Classifier
2023-12-13 19:30:09,164:INFO:Total runtime is 0.10953057607014974 minutes
2023-12-13 19:30:09,164:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:09,178:INFO:Initializing create_model()
2023-12-13 19:30:09,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:09,178:INFO:Checking exceptions
2023-12-13 19:30:09,178:INFO:Importing libraries
2023-12-13 19:30:09,178:INFO:Copying training dataset
2023-12-13 19:30:09,181:INFO:Defining folds
2023-12-13 19:30:09,181:INFO:Declaring metric variables
2023-12-13 19:30:09,181:INFO:Importing untrained model
2023-12-13 19:30:09,191:INFO:K Neighbors Classifier Imported successfully
2023-12-13 19:30:09,199:INFO:Starting cross validation
2023-12-13 19:30:09,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:09,294:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:30:09,294:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:30:09,294:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:30:09,294:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:30:09,294:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:30:09,359:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:30:09,375:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:30:09,390:INFO:Calculating mean and std
2023-12-13 19:30:09,390:INFO:Creating metrics dataframe
2023-12-13 19:30:09,390:INFO:Uploading results into container
2023-12-13 19:30:09,390:INFO:Uploading model into container now
2023-12-13 19:30:09,390:INFO:_master_model_container: 2
2023-12-13 19:30:09,390:INFO:_display_container: 2
2023-12-13 19:30:09,390:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-12-13 19:30:09,406:INFO:create_model() successfully completed......................................
2023-12-13 19:30:09,543:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:09,543:INFO:Creating metrics dataframe
2023-12-13 19:30:09,543:INFO:Initializing Naive Bayes
2023-12-13 19:30:09,543:INFO:Total runtime is 0.11585133075714112 minutes
2023-12-13 19:30:09,543:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:09,559:INFO:Initializing create_model()
2023-12-13 19:30:09,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:09,559:INFO:Checking exceptions
2023-12-13 19:30:09,559:INFO:Importing libraries
2023-12-13 19:30:09,559:INFO:Copying training dataset
2023-12-13 19:30:09,559:INFO:Defining folds
2023-12-13 19:30:09,559:INFO:Declaring metric variables
2023-12-13 19:30:09,559:INFO:Importing untrained model
2023-12-13 19:30:09,574:INFO:Naive Bayes Imported successfully
2023-12-13 19:30:09,579:INFO:Starting cross validation
2023-12-13 19:30:09,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:09,662:INFO:Calculating mean and std
2023-12-13 19:30:09,662:INFO:Creating metrics dataframe
2023-12-13 19:30:09,677:INFO:Uploading results into container
2023-12-13 19:30:09,677:INFO:Uploading model into container now
2023-12-13 19:30:09,677:INFO:_master_model_container: 3
2023-12-13 19:30:09,677:INFO:_display_container: 2
2023-12-13 19:30:09,677:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-12-13 19:30:09,677:INFO:create_model() successfully completed......................................
2023-12-13 19:30:09,817:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:09,817:INFO:Creating metrics dataframe
2023-12-13 19:30:09,829:INFO:Initializing Decision Tree Classifier
2023-12-13 19:30:09,829:INFO:Total runtime is 0.12060830195744833 minutes
2023-12-13 19:30:09,829:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:09,829:INFO:Initializing create_model()
2023-12-13 19:30:09,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:09,829:INFO:Checking exceptions
2023-12-13 19:30:09,829:INFO:Importing libraries
2023-12-13 19:30:09,829:INFO:Copying training dataset
2023-12-13 19:30:09,844:INFO:Defining folds
2023-12-13 19:30:09,844:INFO:Declaring metric variables
2023-12-13 19:30:09,850:INFO:Importing untrained model
2023-12-13 19:30:09,855:INFO:Decision Tree Classifier Imported successfully
2023-12-13 19:30:09,859:INFO:Starting cross validation
2023-12-13 19:30:09,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:09,943:INFO:Calculating mean and std
2023-12-13 19:30:09,943:INFO:Creating metrics dataframe
2023-12-13 19:30:09,959:INFO:Uploading results into container
2023-12-13 19:30:09,959:INFO:Uploading model into container now
2023-12-13 19:30:09,959:INFO:_master_model_container: 4
2023-12-13 19:30:09,959:INFO:_display_container: 2
2023-12-13 19:30:09,959:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best')
2023-12-13 19:30:09,959:INFO:create_model() successfully completed......................................
2023-12-13 19:30:10,074:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:10,074:INFO:Creating metrics dataframe
2023-12-13 19:30:10,090:INFO:Initializing SVM - Linear Kernel
2023-12-13 19:30:10,090:INFO:Total runtime is 0.12496265570322673 minutes
2023-12-13 19:30:10,090:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:10,090:INFO:Initializing create_model()
2023-12-13 19:30:10,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:10,090:INFO:Checking exceptions
2023-12-13 19:30:10,090:INFO:Importing libraries
2023-12-13 19:30:10,090:INFO:Copying training dataset
2023-12-13 19:30:10,149:INFO:Defining folds
2023-12-13 19:30:10,149:INFO:Declaring metric variables
2023-12-13 19:30:10,174:INFO:Importing untrained model
2023-12-13 19:30:10,181:INFO:SVM - Linear Kernel Imported successfully
2023-12-13 19:30:10,195:INFO:Starting cross validation
2023-12-13 19:30:10,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:10,330:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:30:10,330:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,330:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,330:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,330:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,345:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,377:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:30:10,377:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:30:10,377:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,377:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,377:INFO:Calculating mean and std
2023-12-13 19:30:10,377:INFO:Creating metrics dataframe
2023-12-13 19:30:10,377:INFO:Uploading results into container
2023-12-13 19:30:10,377:INFO:Uploading model into container now
2023-12-13 19:30:10,377:INFO:_master_model_container: 5
2023-12-13 19:30:10,377:INFO:_display_container: 2
2023-12-13 19:30:10,377:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4195, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-12-13 19:30:10,377:INFO:create_model() successfully completed......................................
2023-12-13 19:30:10,513:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:10,513:INFO:Creating metrics dataframe
2023-12-13 19:30:10,516:INFO:Initializing Ridge Classifier
2023-12-13 19:30:10,516:INFO:Total runtime is 0.13206351200739544 minutes
2023-12-13 19:30:10,516:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:10,516:INFO:Initializing create_model()
2023-12-13 19:30:10,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:10,516:INFO:Checking exceptions
2023-12-13 19:30:10,516:INFO:Importing libraries
2023-12-13 19:30:10,516:INFO:Copying training dataset
2023-12-13 19:30:10,529:INFO:Defining folds
2023-12-13 19:30:10,529:INFO:Declaring metric variables
2023-12-13 19:30:10,529:INFO:Importing untrained model
2023-12-13 19:30:10,537:INFO:Ridge Classifier Imported successfully
2023-12-13 19:30:10,545:INFO:Starting cross validation
2023-12-13 19:30:10,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:10,592:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,592:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,592:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,592:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,592:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,592:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,592:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,592:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,600:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,600:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,600:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,600:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,600:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,611:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,611:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,611:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,611:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,611:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:30:10,627:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:10,627:INFO:Calculating mean and std
2023-12-13 19:30:10,627:INFO:Creating metrics dataframe
2023-12-13 19:30:10,636:INFO:Uploading results into container
2023-12-13 19:30:10,636:INFO:Uploading model into container now
2023-12-13 19:30:10,636:INFO:_master_model_container: 6
2023-12-13 19:30:10,636:INFO:_display_container: 2
2023-12-13 19:30:10,636:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=4195, solver='auto', tol=0.001)
2023-12-13 19:30:10,636:INFO:create_model() successfully completed......................................
2023-12-13 19:30:10,730:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:10,730:INFO:Creating metrics dataframe
2023-12-13 19:30:10,745:INFO:Initializing Random Forest Classifier
2023-12-13 19:30:10,745:INFO:Total runtime is 0.13588381608327232 minutes
2023-12-13 19:30:10,745:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:10,745:INFO:Initializing create_model()
2023-12-13 19:30:10,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:10,745:INFO:Checking exceptions
2023-12-13 19:30:10,745:INFO:Importing libraries
2023-12-13 19:30:10,745:INFO:Copying training dataset
2023-12-13 19:30:10,745:INFO:Defining folds
2023-12-13 19:30:10,745:INFO:Declaring metric variables
2023-12-13 19:30:10,745:INFO:Importing untrained model
2023-12-13 19:30:10,763:INFO:Random Forest Classifier Imported successfully
2023-12-13 19:30:10,765:INFO:Starting cross validation
2023-12-13 19:30:10,765:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:11,416:INFO:Calculating mean and std
2023-12-13 19:30:11,416:INFO:Creating metrics dataframe
2023-12-13 19:30:11,416:INFO:Uploading results into container
2023-12-13 19:30:11,416:INFO:Uploading model into container now
2023-12-13 19:30:11,416:INFO:_master_model_container: 7
2023-12-13 19:30:11,416:INFO:_display_container: 2
2023-12-13 19:30:11,416:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4195, verbose=0, warm_start=False)
2023-12-13 19:30:11,416:INFO:create_model() successfully completed......................................
2023-12-13 19:30:11,545:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:11,545:INFO:Creating metrics dataframe
2023-12-13 19:30:11,545:INFO:Initializing Quadratic Discriminant Analysis
2023-12-13 19:30:11,545:INFO:Total runtime is 0.14921800295511883 minutes
2023-12-13 19:30:11,558:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:11,563:INFO:Initializing create_model()
2023-12-13 19:30:11,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:11,563:INFO:Checking exceptions
2023-12-13 19:30:11,563:INFO:Importing libraries
2023-12-13 19:30:11,563:INFO:Copying training dataset
2023-12-13 19:30:11,563:INFO:Defining folds
2023-12-13 19:30:11,563:INFO:Declaring metric variables
2023-12-13 19:30:11,563:INFO:Importing untrained model
2023-12-13 19:30:11,563:INFO:Quadratic Discriminant Analysis Imported successfully
2023-12-13 19:30:11,582:INFO:Starting cross validation
2023-12-13 19:30:11,582:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:11,619:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,619:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,619:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,619:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,619:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,619:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,627:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,635:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,649:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,649:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:30:11,669:INFO:Calculating mean and std
2023-12-13 19:30:11,669:INFO:Creating metrics dataframe
2023-12-13 19:30:11,669:INFO:Uploading results into container
2023-12-13 19:30:11,669:INFO:Uploading model into container now
2023-12-13 19:30:11,669:INFO:_master_model_container: 8
2023-12-13 19:30:11,669:INFO:_display_container: 2
2023-12-13 19:30:11,669:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-12-13 19:30:11,677:INFO:create_model() successfully completed......................................
2023-12-13 19:30:11,782:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:11,782:INFO:Creating metrics dataframe
2023-12-13 19:30:11,797:INFO:Initializing Ada Boost Classifier
2023-12-13 19:30:11,797:INFO:Total runtime is 0.15341597000757856 minutes
2023-12-13 19:30:11,797:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:11,797:INFO:Initializing create_model()
2023-12-13 19:30:11,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:11,797:INFO:Checking exceptions
2023-12-13 19:30:11,797:INFO:Importing libraries
2023-12-13 19:30:11,797:INFO:Copying training dataset
2023-12-13 19:30:11,809:INFO:Defining folds
2023-12-13 19:30:11,809:INFO:Declaring metric variables
2023-12-13 19:30:11,809:INFO:Importing untrained model
2023-12-13 19:30:11,814:INFO:Ada Boost Classifier Imported successfully
2023-12-13 19:30:11,814:INFO:Starting cross validation
2023-12-13 19:30:11,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:12,061:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,061:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,077:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,077:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,077:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,077:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,077:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,092:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,191:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,191:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:12,191:INFO:Calculating mean and std
2023-12-13 19:30:12,191:INFO:Creating metrics dataframe
2023-12-13 19:30:12,208:INFO:Uploading results into container
2023-12-13 19:30:12,208:INFO:Uploading model into container now
2023-12-13 19:30:12,208:INFO:_master_model_container: 9
2023-12-13 19:30:12,208:INFO:_display_container: 2
2023-12-13 19:30:12,208:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4195)
2023-12-13 19:30:12,208:INFO:create_model() successfully completed......................................
2023-12-13 19:30:12,310:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:12,310:INFO:Creating metrics dataframe
2023-12-13 19:30:12,330:INFO:Initializing Gradient Boosting Classifier
2023-12-13 19:30:12,330:INFO:Total runtime is 0.16229337851206466 minutes
2023-12-13 19:30:12,340:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:12,340:INFO:Initializing create_model()
2023-12-13 19:30:12,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:12,340:INFO:Checking exceptions
2023-12-13 19:30:12,340:INFO:Importing libraries
2023-12-13 19:30:12,340:INFO:Copying training dataset
2023-12-13 19:30:12,342:INFO:Defining folds
2023-12-13 19:30:12,342:INFO:Declaring metric variables
2023-12-13 19:30:12,350:INFO:Importing untrained model
2023-12-13 19:30:12,354:INFO:Gradient Boosting Classifier Imported successfully
2023-12-13 19:30:12,365:INFO:Starting cross validation
2023-12-13 19:30:12,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:15,166:INFO:Calculating mean and std
2023-12-13 19:30:15,166:INFO:Creating metrics dataframe
2023-12-13 19:30:15,178:INFO:Uploading results into container
2023-12-13 19:30:15,178:INFO:Uploading model into container now
2023-12-13 19:30:15,181:INFO:_master_model_container: 10
2023-12-13 19:30:15,181:INFO:_display_container: 2
2023-12-13 19:30:15,182:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4195, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-12-13 19:30:15,182:INFO:create_model() successfully completed......................................
2023-12-13 19:30:15,331:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:15,331:INFO:Creating metrics dataframe
2023-12-13 19:30:15,347:INFO:Initializing Linear Discriminant Analysis
2023-12-13 19:30:15,347:INFO:Total runtime is 0.21258574724197393 minutes
2023-12-13 19:30:15,347:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:15,347:INFO:Initializing create_model()
2023-12-13 19:30:15,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:15,347:INFO:Checking exceptions
2023-12-13 19:30:15,347:INFO:Importing libraries
2023-12-13 19:30:15,347:INFO:Copying training dataset
2023-12-13 19:30:15,362:INFO:Defining folds
2023-12-13 19:30:15,362:INFO:Declaring metric variables
2023-12-13 19:30:15,365:INFO:Importing untrained model
2023-12-13 19:30:15,369:INFO:Linear Discriminant Analysis Imported successfully
2023-12-13 19:30:15,376:INFO:Starting cross validation
2023-12-13 19:30:15,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:15,475:INFO:Calculating mean and std
2023-12-13 19:30:15,479:INFO:Creating metrics dataframe
2023-12-13 19:30:15,479:INFO:Uploading results into container
2023-12-13 19:30:15,479:INFO:Uploading model into container now
2023-12-13 19:30:15,479:INFO:_master_model_container: 11
2023-12-13 19:30:15,479:INFO:_display_container: 2
2023-12-13 19:30:15,479:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-12-13 19:30:15,479:INFO:create_model() successfully completed......................................
2023-12-13 19:30:15,609:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:15,609:INFO:Creating metrics dataframe
2023-12-13 19:30:15,609:INFO:Initializing Extra Trees Classifier
2023-12-13 19:30:15,609:INFO:Total runtime is 0.21694257259368901 minutes
2023-12-13 19:30:15,625:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:15,625:INFO:Initializing create_model()
2023-12-13 19:30:15,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:15,625:INFO:Checking exceptions
2023-12-13 19:30:15,625:INFO:Importing libraries
2023-12-13 19:30:15,625:INFO:Copying training dataset
2023-12-13 19:30:15,625:INFO:Defining folds
2023-12-13 19:30:15,625:INFO:Declaring metric variables
2023-12-13 19:30:15,625:INFO:Importing untrained model
2023-12-13 19:30:15,641:INFO:Extra Trees Classifier Imported successfully
2023-12-13 19:30:15,646:INFO:Starting cross validation
2023-12-13 19:30:15,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:16,232:INFO:Calculating mean and std
2023-12-13 19:30:16,232:INFO:Creating metrics dataframe
2023-12-13 19:30:16,232:INFO:Uploading results into container
2023-12-13 19:30:16,232:INFO:Uploading model into container now
2023-12-13 19:30:16,232:INFO:_master_model_container: 12
2023-12-13 19:30:16,232:INFO:_display_container: 2
2023-12-13 19:30:16,232:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4195, verbose=0, warm_start=False)
2023-12-13 19:30:16,232:INFO:create_model() successfully completed......................................
2023-12-13 19:30:16,396:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:16,396:INFO:Creating metrics dataframe
2023-12-13 19:30:16,396:INFO:Initializing Extreme Gradient Boosting
2023-12-13 19:30:16,396:INFO:Total runtime is 0.23006765445073452 minutes
2023-12-13 19:30:16,412:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:16,412:INFO:Initializing create_model()
2023-12-13 19:30:16,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:16,412:INFO:Checking exceptions
2023-12-13 19:30:16,412:INFO:Importing libraries
2023-12-13 19:30:16,412:INFO:Copying training dataset
2023-12-13 19:30:16,412:INFO:Defining folds
2023-12-13 19:30:16,412:INFO:Declaring metric variables
2023-12-13 19:30:16,423:INFO:Importing untrained model
2023-12-13 19:30:16,430:INFO:Extreme Gradient Boosting Imported successfully
2023-12-13 19:30:16,430:INFO:Starting cross validation
2023-12-13 19:30:16,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:17,144:INFO:Calculating mean and std
2023-12-13 19:30:17,144:INFO:Creating metrics dataframe
2023-12-13 19:30:17,144:INFO:Uploading results into container
2023-12-13 19:30:17,144:INFO:Uploading model into container now
2023-12-13 19:30:17,144:INFO:_master_model_container: 13
2023-12-13 19:30:17,144:INFO:_display_container: 2
2023-12-13 19:30:17,144:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-12-13 19:30:17,144:INFO:create_model() successfully completed......................................
2023-12-13 19:30:17,264:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:17,264:INFO:Creating metrics dataframe
2023-12-13 19:30:17,278:INFO:Initializing Light Gradient Boosting Machine
2023-12-13 19:30:17,286:INFO:Total runtime is 0.2449002901713054 minutes
2023-12-13 19:30:17,290:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:17,290:INFO:Initializing create_model()
2023-12-13 19:30:17,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:17,290:INFO:Checking exceptions
2023-12-13 19:30:17,290:INFO:Importing libraries
2023-12-13 19:30:17,290:INFO:Copying training dataset
2023-12-13 19:30:17,297:INFO:Defining folds
2023-12-13 19:30:17,297:INFO:Declaring metric variables
2023-12-13 19:30:17,297:INFO:Importing untrained model
2023-12-13 19:30:17,297:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-13 19:30:17,312:INFO:Starting cross validation
2023-12-13 19:30:17,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:19,596:INFO:Calculating mean and std
2023-12-13 19:30:19,596:INFO:Creating metrics dataframe
2023-12-13 19:30:19,616:INFO:Uploading results into container
2023-12-13 19:30:19,616:INFO:Uploading model into container now
2023-12-13 19:30:19,616:INFO:_master_model_container: 14
2023-12-13 19:30:19,616:INFO:_display_container: 2
2023-12-13 19:30:19,616:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4195, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-13 19:30:19,616:INFO:create_model() successfully completed......................................
2023-12-13 19:30:19,740:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:19,740:INFO:Creating metrics dataframe
2023-12-13 19:30:19,756:INFO:Initializing Dummy Classifier
2023-12-13 19:30:19,756:INFO:Total runtime is 0.2860628247261048 minutes
2023-12-13 19:30:19,756:INFO:SubProcess create_model() called ==================================
2023-12-13 19:30:19,756:INFO:Initializing create_model()
2023-12-13 19:30:19,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218AFDF6380>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:19,756:INFO:Checking exceptions
2023-12-13 19:30:19,756:INFO:Importing libraries
2023-12-13 19:30:19,756:INFO:Copying training dataset
2023-12-13 19:30:19,772:INFO:Defining folds
2023-12-13 19:30:19,772:INFO:Declaring metric variables
2023-12-13 19:30:19,777:INFO:Importing untrained model
2023-12-13 19:30:19,781:INFO:Dummy Classifier Imported successfully
2023-12-13 19:30:19,794:INFO:Starting cross validation
2023-12-13 19:30:19,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:30:19,833:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,833:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,833:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,833:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,833:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,841:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,849:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,851:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,860:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,863:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:30:19,863:INFO:Calculating mean and std
2023-12-13 19:30:19,863:INFO:Creating metrics dataframe
2023-12-13 19:30:19,863:INFO:Uploading results into container
2023-12-13 19:30:19,863:INFO:Uploading model into container now
2023-12-13 19:30:19,863:INFO:_master_model_container: 15
2023-12-13 19:30:19,863:INFO:_display_container: 2
2023-12-13 19:30:19,863:INFO:DummyClassifier(constant=None, random_state=4195, strategy='prior')
2023-12-13 19:30:19,863:INFO:create_model() successfully completed......................................
2023-12-13 19:30:19,974:INFO:SubProcess create_model() end ==================================
2023-12-13 19:30:19,974:INFO:Creating metrics dataframe
2023-12-13 19:30:19,995:INFO:Initializing create_model()
2023-12-13 19:30:19,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4195, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:30:19,995:INFO:Checking exceptions
2023-12-13 19:30:19,995:INFO:Importing libraries
2023-12-13 19:30:19,995:INFO:Copying training dataset
2023-12-13 19:30:19,995:INFO:Defining folds
2023-12-13 19:30:19,995:INFO:Declaring metric variables
2023-12-13 19:30:19,995:INFO:Importing untrained model
2023-12-13 19:30:19,995:INFO:Declaring custom model
2023-12-13 19:30:19,995:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-13 19:30:19,995:INFO:Cross validation set to False
2023-12-13 19:30:19,995:INFO:Fitting Model
2023-12-13 19:30:20,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2023-12-13 19:30:20,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-13 19:30:20,013:INFO:[LightGBM] [Info] Total Bins 575
2023-12-13 19:30:20,013:INFO:[LightGBM] [Info] Number of data points in the train set: 2083, number of used features: 9
2023-12-13 19:30:20,013:INFO:[LightGBM] [Info] Start training from score -2.280272
2023-12-13 19:30:20,013:INFO:[LightGBM] [Info] Start training from score -0.578516
2023-12-13 19:30:20,013:INFO:[LightGBM] [Info] Start training from score -2.225464
2023-12-13 19:30:20,013:INFO:[LightGBM] [Info] Start training from score -1.474048
2023-12-13 19:30:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:30:20,186:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4195, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-13 19:30:20,186:INFO:create_model() successfully completed......................................
2023-12-13 19:30:20,362:INFO:_master_model_container: 15
2023-12-13 19:30:20,362:INFO:_display_container: 2
2023-12-13 19:30:20,362:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4195, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-13 19:30:20,362:INFO:compare_models() successfully completed......................................
2023-12-13 19:32:59,557:INFO:Initializing compare_models()
2023-12-13 19:32:59,557:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-12-13 19:32:59,557:INFO:Checking exceptions
2023-12-13 19:32:59,557:INFO:Preparing display monitor
2023-12-13 19:32:59,606:INFO:Initializing Logistic Regression
2023-12-13 19:32:59,606:INFO:Total runtime is 0.0 minutes
2023-12-13 19:32:59,606:INFO:SubProcess create_model() called ==================================
2023-12-13 19:32:59,606:INFO:Initializing create_model()
2023-12-13 19:32:59,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:32:59,606:INFO:Checking exceptions
2023-12-13 19:32:59,606:INFO:Importing libraries
2023-12-13 19:32:59,606:INFO:Copying training dataset
2023-12-13 19:32:59,615:INFO:Defining folds
2023-12-13 19:32:59,615:INFO:Declaring metric variables
2023-12-13 19:32:59,615:INFO:Importing untrained model
2023-12-13 19:32:59,622:INFO:Logistic Regression Imported successfully
2023-12-13 19:32:59,625:INFO:Starting cross validation
2023-12-13 19:32:59,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:00,975:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,045:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,060:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,060:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,158:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,158:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,158:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,174:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,639:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,676:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-13 19:33:01,692:INFO:Calculating mean and std
2023-12-13 19:33:01,692:INFO:Creating metrics dataframe
2023-12-13 19:33:01,708:INFO:Uploading results into container
2023-12-13 19:33:01,708:INFO:Uploading model into container now
2023-12-13 19:33:01,708:INFO:_master_model_container: 16
2023-12-13 19:33:01,708:INFO:_display_container: 3
2023-12-13 19:33:01,708:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4195, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-12-13 19:33:01,708:INFO:create_model() successfully completed......................................
2023-12-13 19:33:01,823:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:01,823:INFO:Creating metrics dataframe
2023-12-13 19:33:01,823:INFO:Initializing K Neighbors Classifier
2023-12-13 19:33:01,823:INFO:Total runtime is 0.03693818251291911 minutes
2023-12-13 19:33:01,823:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:01,823:INFO:Initializing create_model()
2023-12-13 19:33:01,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:01,823:INFO:Checking exceptions
2023-12-13 19:33:01,823:INFO:Importing libraries
2023-12-13 19:33:01,823:INFO:Copying training dataset
2023-12-13 19:33:01,838:INFO:Defining folds
2023-12-13 19:33:01,838:INFO:Declaring metric variables
2023-12-13 19:33:01,846:INFO:Importing untrained model
2023-12-13 19:33:01,846:INFO:K Neighbors Classifier Imported successfully
2023-12-13 19:33:01,846:INFO:Starting cross validation
2023-12-13 19:33:01,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:01,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,914:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,914:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,924:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,972:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,972:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-13 19:33:01,992:INFO:Calculating mean and std
2023-12-13 19:33:01,992:INFO:Creating metrics dataframe
2023-12-13 19:33:01,992:INFO:Uploading results into container
2023-12-13 19:33:01,992:INFO:Uploading model into container now
2023-12-13 19:33:01,992:INFO:_master_model_container: 17
2023-12-13 19:33:01,992:INFO:_display_container: 3
2023-12-13 19:33:01,992:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-12-13 19:33:01,992:INFO:create_model() successfully completed......................................
2023-12-13 19:33:02,093:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:02,093:INFO:Creating metrics dataframe
2023-12-13 19:33:02,109:INFO:Initializing Naive Bayes
2023-12-13 19:33:02,109:INFO:Total runtime is 0.04170449177424113 minutes
2023-12-13 19:33:02,109:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:02,109:INFO:Initializing create_model()
2023-12-13 19:33:02,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:02,109:INFO:Checking exceptions
2023-12-13 19:33:02,109:INFO:Importing libraries
2023-12-13 19:33:02,109:INFO:Copying training dataset
2023-12-13 19:33:02,109:INFO:Defining folds
2023-12-13 19:33:02,109:INFO:Declaring metric variables
2023-12-13 19:33:02,109:INFO:Importing untrained model
2023-12-13 19:33:02,126:INFO:Naive Bayes Imported successfully
2023-12-13 19:33:02,126:INFO:Starting cross validation
2023-12-13 19:33:02,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:02,206:INFO:Calculating mean and std
2023-12-13 19:33:02,206:INFO:Creating metrics dataframe
2023-12-13 19:33:02,206:INFO:Uploading results into container
2023-12-13 19:33:02,206:INFO:Uploading model into container now
2023-12-13 19:33:02,206:INFO:_master_model_container: 18
2023-12-13 19:33:02,206:INFO:_display_container: 3
2023-12-13 19:33:02,206:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-12-13 19:33:02,206:INFO:create_model() successfully completed......................................
2023-12-13 19:33:02,309:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:02,309:INFO:Creating metrics dataframe
2023-12-13 19:33:02,309:INFO:Initializing Decision Tree Classifier
2023-12-13 19:33:02,309:INFO:Total runtime is 0.04503527482350668 minutes
2023-12-13 19:33:02,324:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:02,324:INFO:Initializing create_model()
2023-12-13 19:33:02,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:02,324:INFO:Checking exceptions
2023-12-13 19:33:02,324:INFO:Importing libraries
2023-12-13 19:33:02,324:INFO:Copying training dataset
2023-12-13 19:33:02,324:INFO:Defining folds
2023-12-13 19:33:02,324:INFO:Declaring metric variables
2023-12-13 19:33:02,335:INFO:Importing untrained model
2023-12-13 19:33:02,335:INFO:Decision Tree Classifier Imported successfully
2023-12-13 19:33:02,343:INFO:Starting cross validation
2023-12-13 19:33:02,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:02,423:INFO:Calculating mean and std
2023-12-13 19:33:02,423:INFO:Creating metrics dataframe
2023-12-13 19:33:02,423:INFO:Uploading results into container
2023-12-13 19:33:02,423:INFO:Uploading model into container now
2023-12-13 19:33:02,423:INFO:_master_model_container: 19
2023-12-13 19:33:02,423:INFO:_display_container: 3
2023-12-13 19:33:02,423:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best')
2023-12-13 19:33:02,423:INFO:create_model() successfully completed......................................
2023-12-13 19:33:02,525:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:02,525:INFO:Creating metrics dataframe
2023-12-13 19:33:02,541:INFO:Initializing SVM - Linear Kernel
2023-12-13 19:33:02,541:INFO:Total runtime is 0.04891089995702108 minutes
2023-12-13 19:33:02,541:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:02,541:INFO:Initializing create_model()
2023-12-13 19:33:02,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:02,541:INFO:Checking exceptions
2023-12-13 19:33:02,541:INFO:Importing libraries
2023-12-13 19:33:02,541:INFO:Copying training dataset
2023-12-13 19:33:02,541:INFO:Defining folds
2023-12-13 19:33:02,541:INFO:Declaring metric variables
2023-12-13 19:33:02,541:INFO:Importing untrained model
2023-12-13 19:33:02,559:INFO:SVM - Linear Kernel Imported successfully
2023-12-13 19:33:02,559:INFO:Starting cross validation
2023-12-13 19:33:02,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,673:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,673:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,681:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,681:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,681:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,697:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,697:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,697:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-13 19:33:02,697:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,712:INFO:Calculating mean and std
2023-12-13 19:33:02,712:INFO:Creating metrics dataframe
2023-12-13 19:33:02,712:INFO:Uploading results into container
2023-12-13 19:33:02,712:INFO:Uploading model into container now
2023-12-13 19:33:02,712:INFO:_master_model_container: 20
2023-12-13 19:33:02,712:INFO:_display_container: 3
2023-12-13 19:33:02,712:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4195, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-12-13 19:33:02,712:INFO:create_model() successfully completed......................................
2023-12-13 19:33:02,828:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:02,828:INFO:Creating metrics dataframe
2023-12-13 19:33:02,828:INFO:Initializing Ridge Classifier
2023-12-13 19:33:02,828:INFO:Total runtime is 0.053695547580719 minutes
2023-12-13 19:33:02,828:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:02,828:INFO:Initializing create_model()
2023-12-13 19:33:02,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:02,828:INFO:Checking exceptions
2023-12-13 19:33:02,828:INFO:Importing libraries
2023-12-13 19:33:02,828:INFO:Copying training dataset
2023-12-13 19:33:02,844:INFO:Defining folds
2023-12-13 19:33:02,844:INFO:Declaring metric variables
2023-12-13 19:33:02,844:INFO:Importing untrained model
2023-12-13 19:33:02,853:INFO:Ridge Classifier Imported successfully
2023-12-13 19:33:02,856:INFO:Starting cross validation
2023-12-13 19:33:02,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:02,895:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,895:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,906:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,914:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,914:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,914:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,928:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,928:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,928:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,928:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-13 19:33:02,928:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,928:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:02,928:INFO:Calculating mean and std
2023-12-13 19:33:02,939:INFO:Creating metrics dataframe
2023-12-13 19:33:02,940:INFO:Uploading results into container
2023-12-13 19:33:02,940:INFO:Uploading model into container now
2023-12-13 19:33:02,940:INFO:_master_model_container: 21
2023-12-13 19:33:02,940:INFO:_display_container: 3
2023-12-13 19:33:02,940:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=4195, solver='auto', tol=0.001)
2023-12-13 19:33:02,940:INFO:create_model() successfully completed......................................
2023-12-13 19:33:03,039:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:03,039:INFO:Creating metrics dataframe
2023-12-13 19:33:03,048:INFO:Initializing Random Forest Classifier
2023-12-13 19:33:03,048:INFO:Total runtime is 0.05735652049382528 minutes
2023-12-13 19:33:03,048:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:03,048:INFO:Initializing create_model()
2023-12-13 19:33:03,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:03,048:INFO:Checking exceptions
2023-12-13 19:33:03,048:INFO:Importing libraries
2023-12-13 19:33:03,048:INFO:Copying training dataset
2023-12-13 19:33:03,048:INFO:Defining folds
2023-12-13 19:33:03,048:INFO:Declaring metric variables
2023-12-13 19:33:03,048:INFO:Importing untrained model
2023-12-13 19:33:03,065:INFO:Random Forest Classifier Imported successfully
2023-12-13 19:33:03,065:INFO:Starting cross validation
2023-12-13 19:33:03,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:03,691:INFO:Calculating mean and std
2023-12-13 19:33:03,691:INFO:Creating metrics dataframe
2023-12-13 19:33:03,707:INFO:Uploading results into container
2023-12-13 19:33:03,707:INFO:Uploading model into container now
2023-12-13 19:33:03,707:INFO:_master_model_container: 22
2023-12-13 19:33:03,707:INFO:_display_container: 3
2023-12-13 19:33:03,710:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4195, verbose=0, warm_start=False)
2023-12-13 19:33:03,710:INFO:create_model() successfully completed......................................
2023-12-13 19:33:03,807:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:03,807:INFO:Creating metrics dataframe
2023-12-13 19:33:03,824:INFO:Initializing Quadratic Discriminant Analysis
2023-12-13 19:33:03,824:INFO:Total runtime is 0.07028832435607911 minutes
2023-12-13 19:33:03,824:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:03,824:INFO:Initializing create_model()
2023-12-13 19:33:03,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:03,824:INFO:Checking exceptions
2023-12-13 19:33:03,824:INFO:Importing libraries
2023-12-13 19:33:03,824:INFO:Copying training dataset
2023-12-13 19:33:03,824:INFO:Defining folds
2023-12-13 19:33:03,824:INFO:Declaring metric variables
2023-12-13 19:33:03,824:INFO:Importing untrained model
2023-12-13 19:33:03,839:INFO:Quadratic Discriminant Analysis Imported successfully
2023-12-13 19:33:03,843:INFO:Starting cross validation
2023-12-13 19:33:03,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:03,861:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,873:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,873:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,873:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,873:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,881:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,881:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,881:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,907:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,907:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-13 19:33:03,924:INFO:Calculating mean and std
2023-12-13 19:33:03,924:INFO:Creating metrics dataframe
2023-12-13 19:33:03,924:INFO:Uploading results into container
2023-12-13 19:33:03,924:INFO:Uploading model into container now
2023-12-13 19:33:03,924:INFO:_master_model_container: 23
2023-12-13 19:33:03,924:INFO:_display_container: 3
2023-12-13 19:33:03,924:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-12-13 19:33:03,924:INFO:create_model() successfully completed......................................
2023-12-13 19:33:04,029:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:04,029:INFO:Creating metrics dataframe
2023-12-13 19:33:04,039:INFO:Initializing Ada Boost Classifier
2023-12-13 19:33:04,039:INFO:Total runtime is 0.07387695709864299 minutes
2023-12-13 19:33:04,045:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:04,045:INFO:Initializing create_model()
2023-12-13 19:33:04,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:04,045:INFO:Checking exceptions
2023-12-13 19:33:04,045:INFO:Importing libraries
2023-12-13 19:33:04,045:INFO:Copying training dataset
2023-12-13 19:33:04,045:INFO:Defining folds
2023-12-13 19:33:04,045:INFO:Declaring metric variables
2023-12-13 19:33:04,045:INFO:Importing untrained model
2023-12-13 19:33:04,056:INFO:Ada Boost Classifier Imported successfully
2023-12-13 19:33:04,059:INFO:Starting cross validation
2023-12-13 19:33:04,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:04,277:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,292:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,292:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,292:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,292:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,308:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,308:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,308:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,422:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,422:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:04,422:INFO:Calculating mean and std
2023-12-13 19:33:04,422:INFO:Creating metrics dataframe
2023-12-13 19:33:04,422:INFO:Uploading results into container
2023-12-13 19:33:04,422:INFO:Uploading model into container now
2023-12-13 19:33:04,422:INFO:_master_model_container: 24
2023-12-13 19:33:04,422:INFO:_display_container: 3
2023-12-13 19:33:04,422:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4195)
2023-12-13 19:33:04,422:INFO:create_model() successfully completed......................................
2023-12-13 19:33:04,532:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:04,532:INFO:Creating metrics dataframe
2023-12-13 19:33:04,547:INFO:Initializing Gradient Boosting Classifier
2023-12-13 19:33:04,547:INFO:Total runtime is 0.08234783013661703 minutes
2023-12-13 19:33:04,556:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:04,556:INFO:Initializing create_model()
2023-12-13 19:33:04,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:04,556:INFO:Checking exceptions
2023-12-13 19:33:04,556:INFO:Importing libraries
2023-12-13 19:33:04,556:INFO:Copying training dataset
2023-12-13 19:33:04,561:INFO:Defining folds
2023-12-13 19:33:04,561:INFO:Declaring metric variables
2023-12-13 19:33:04,561:INFO:Importing untrained model
2023-12-13 19:33:04,561:INFO:Gradient Boosting Classifier Imported successfully
2023-12-13 19:33:04,572:INFO:Starting cross validation
2023-12-13 19:33:04,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:06,958:INFO:Calculating mean and std
2023-12-13 19:33:06,958:INFO:Creating metrics dataframe
2023-12-13 19:33:06,958:INFO:Uploading results into container
2023-12-13 19:33:06,958:INFO:Uploading model into container now
2023-12-13 19:33:06,958:INFO:_master_model_container: 25
2023-12-13 19:33:06,958:INFO:_display_container: 3
2023-12-13 19:33:06,958:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4195, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-12-13 19:33:06,958:INFO:create_model() successfully completed......................................
2023-12-13 19:33:07,059:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:07,059:INFO:Creating metrics dataframe
2023-12-13 19:33:07,074:INFO:Initializing Linear Discriminant Analysis
2023-12-13 19:33:07,074:INFO:Total runtime is 0.12446048657099407 minutes
2023-12-13 19:33:07,083:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:07,083:INFO:Initializing create_model()
2023-12-13 19:33:07,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:07,083:INFO:Checking exceptions
2023-12-13 19:33:07,083:INFO:Importing libraries
2023-12-13 19:33:07,083:INFO:Copying training dataset
2023-12-13 19:33:07,083:INFO:Defining folds
2023-12-13 19:33:07,083:INFO:Declaring metric variables
2023-12-13 19:33:07,092:INFO:Importing untrained model
2023-12-13 19:33:07,092:INFO:Linear Discriminant Analysis Imported successfully
2023-12-13 19:33:07,092:INFO:Starting cross validation
2023-12-13 19:33:07,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:07,180:INFO:Calculating mean and std
2023-12-13 19:33:07,180:INFO:Creating metrics dataframe
2023-12-13 19:33:07,180:INFO:Uploading results into container
2023-12-13 19:33:07,180:INFO:Uploading model into container now
2023-12-13 19:33:07,180:INFO:_master_model_container: 26
2023-12-13 19:33:07,180:INFO:_display_container: 3
2023-12-13 19:33:07,180:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-12-13 19:33:07,180:INFO:create_model() successfully completed......................................
2023-12-13 19:33:07,292:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:07,292:INFO:Creating metrics dataframe
2023-12-13 19:33:07,292:INFO:Initializing Extra Trees Classifier
2023-12-13 19:33:07,292:INFO:Total runtime is 0.1280892888704936 minutes
2023-12-13 19:33:07,292:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:07,292:INFO:Initializing create_model()
2023-12-13 19:33:07,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:07,292:INFO:Checking exceptions
2023-12-13 19:33:07,292:INFO:Importing libraries
2023-12-13 19:33:07,292:INFO:Copying training dataset
2023-12-13 19:33:07,307:INFO:Defining folds
2023-12-13 19:33:07,307:INFO:Declaring metric variables
2023-12-13 19:33:07,316:INFO:Importing untrained model
2023-12-13 19:33:07,316:INFO:Extra Trees Classifier Imported successfully
2023-12-13 19:33:07,322:INFO:Starting cross validation
2023-12-13 19:33:07,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:07,872:INFO:Calculating mean and std
2023-12-13 19:33:07,872:INFO:Creating metrics dataframe
2023-12-13 19:33:07,888:INFO:Uploading results into container
2023-12-13 19:33:07,889:INFO:Uploading model into container now
2023-12-13 19:33:07,889:INFO:_master_model_container: 27
2023-12-13 19:33:07,889:INFO:_display_container: 3
2023-12-13 19:33:07,889:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4195, verbose=0, warm_start=False)
2023-12-13 19:33:07,889:INFO:create_model() successfully completed......................................
2023-12-13 19:33:07,989:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:07,989:INFO:Creating metrics dataframe
2023-12-13 19:33:08,009:INFO:Initializing Extreme Gradient Boosting
2023-12-13 19:33:08,009:INFO:Total runtime is 0.1400493899981181 minutes
2023-12-13 19:33:08,015:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:08,015:INFO:Initializing create_model()
2023-12-13 19:33:08,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:08,015:INFO:Checking exceptions
2023-12-13 19:33:08,015:INFO:Importing libraries
2023-12-13 19:33:08,015:INFO:Copying training dataset
2023-12-13 19:33:08,015:INFO:Defining folds
2023-12-13 19:33:08,015:INFO:Declaring metric variables
2023-12-13 19:33:08,022:INFO:Importing untrained model
2023-12-13 19:33:08,022:INFO:Extreme Gradient Boosting Imported successfully
2023-12-13 19:33:08,030:INFO:Starting cross validation
2023-12-13 19:33:08,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:09,023:INFO:Calculating mean and std
2023-12-13 19:33:09,023:INFO:Creating metrics dataframe
2023-12-13 19:33:09,023:INFO:Uploading results into container
2023-12-13 19:33:09,023:INFO:Uploading model into container now
2023-12-13 19:33:09,023:INFO:_master_model_container: 28
2023-12-13 19:33:09,023:INFO:_display_container: 3
2023-12-13 19:33:09,023:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-12-13 19:33:09,023:INFO:create_model() successfully completed......................................
2023-12-13 19:33:09,158:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:09,158:INFO:Creating metrics dataframe
2023-12-13 19:33:09,173:INFO:Initializing Light Gradient Boosting Machine
2023-12-13 19:33:09,173:INFO:Total runtime is 0.1594412167867025 minutes
2023-12-13 19:33:09,178:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:09,178:INFO:Initializing create_model()
2023-12-13 19:33:09,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:09,178:INFO:Checking exceptions
2023-12-13 19:33:09,178:INFO:Importing libraries
2023-12-13 19:33:09,178:INFO:Copying training dataset
2023-12-13 19:33:09,178:INFO:Defining folds
2023-12-13 19:33:09,178:INFO:Declaring metric variables
2023-12-13 19:33:09,178:INFO:Importing untrained model
2023-12-13 19:33:09,192:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-13 19:33:09,192:INFO:Starting cross validation
2023-12-13 19:33:09,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:11,156:INFO:Calculating mean and std
2023-12-13 19:33:11,156:INFO:Creating metrics dataframe
2023-12-13 19:33:11,173:INFO:Uploading results into container
2023-12-13 19:33:11,173:INFO:Uploading model into container now
2023-12-13 19:33:11,173:INFO:_master_model_container: 29
2023-12-13 19:33:11,173:INFO:_display_container: 3
2023-12-13 19:33:11,173:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4195, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-13 19:33:11,173:INFO:create_model() successfully completed......................................
2023-12-13 19:33:11,309:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:11,309:INFO:Creating metrics dataframe
2023-12-13 19:33:11,322:INFO:Initializing Dummy Classifier
2023-12-13 19:33:11,322:INFO:Total runtime is 0.19526005585988365 minutes
2023-12-13 19:33:11,327:INFO:SubProcess create_model() called ==================================
2023-12-13 19:33:11,327:INFO:Initializing create_model()
2023-12-13 19:33:11,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218B16B7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:11,327:INFO:Checking exceptions
2023-12-13 19:33:11,327:INFO:Importing libraries
2023-12-13 19:33:11,327:INFO:Copying training dataset
2023-12-13 19:33:11,327:INFO:Defining folds
2023-12-13 19:33:11,327:INFO:Declaring metric variables
2023-12-13 19:33:11,327:INFO:Importing untrained model
2023-12-13 19:33:11,342:INFO:Dummy Classifier Imported successfully
2023-12-13 19:33:11,342:INFO:Starting cross validation
2023-12-13 19:33:11,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-13 19:33:11,388:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,388:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,388:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,388:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,388:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,396:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,396:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,414:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,414:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,414:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-13 19:33:11,422:INFO:Calculating mean and std
2023-12-13 19:33:11,423:INFO:Creating metrics dataframe
2023-12-13 19:33:11,423:INFO:Uploading results into container
2023-12-13 19:33:11,423:INFO:Uploading model into container now
2023-12-13 19:33:11,423:INFO:_master_model_container: 30
2023-12-13 19:33:11,423:INFO:_display_container: 3
2023-12-13 19:33:11,423:INFO:DummyClassifier(constant=None, random_state=4195, strategy='prior')
2023-12-13 19:33:11,423:INFO:create_model() successfully completed......................................
2023-12-13 19:33:11,528:INFO:SubProcess create_model() end ==================================
2023-12-13 19:33:11,528:INFO:Creating metrics dataframe
2023-12-13 19:33:11,555:INFO:Initializing create_model()
2023-12-13 19:33:11,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4195, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:11,555:INFO:Checking exceptions
2023-12-13 19:33:11,559:INFO:Importing libraries
2023-12-13 19:33:11,559:INFO:Copying training dataset
2023-12-13 19:33:11,559:INFO:Defining folds
2023-12-13 19:33:11,559:INFO:Declaring metric variables
2023-12-13 19:33:11,559:INFO:Importing untrained model
2023-12-13 19:33:11,559:INFO:Declaring custom model
2023-12-13 19:33:11,559:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-13 19:33:11,559:INFO:Cross validation set to False
2023-12-13 19:33:11,559:INFO:Fitting Model
2023-12-13 19:33:11,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2023-12-13 19:33:11,572:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-13 19:33:11,572:INFO:[LightGBM] [Info] Total Bins 575
2023-12-13 19:33:11,572:INFO:[LightGBM] [Info] Number of data points in the train set: 2083, number of used features: 9
2023-12-13 19:33:11,572:INFO:[LightGBM] [Info] Start training from score -2.280272
2023-12-13 19:33:11,572:INFO:[LightGBM] [Info] Start training from score -0.578516
2023-12-13 19:33:11,572:INFO:[LightGBM] [Info] Start training from score -2.225464
2023-12-13 19:33:11,572:INFO:[LightGBM] [Info] Start training from score -1.474048
2023-12-13 19:33:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-13 19:33:11,744:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4195, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-13 19:33:11,744:INFO:create_model() successfully completed......................................
2023-12-13 19:33:11,873:INFO:Initializing create_model()
2023-12-13 19:33:11,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:11,878:INFO:Checking exceptions
2023-12-13 19:33:11,880:INFO:Importing libraries
2023-12-13 19:33:11,880:INFO:Copying training dataset
2023-12-13 19:33:11,880:INFO:Defining folds
2023-12-13 19:33:11,880:INFO:Declaring metric variables
2023-12-13 19:33:11,880:INFO:Importing untrained model
2023-12-13 19:33:11,880:INFO:Declaring custom model
2023-12-13 19:33:11,880:INFO:Extreme Gradient Boosting Imported successfully
2023-12-13 19:33:11,880:INFO:Cross validation set to False
2023-12-13 19:33:11,880:INFO:Fitting Model
2023-12-13 19:33:12,006:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='multi:softprob', predictor=None, ...)
2023-12-13 19:33:12,006:INFO:create_model() successfully completed......................................
2023-12-13 19:33:12,139:INFO:Initializing create_model()
2023-12-13 19:33:12,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4195, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:12,139:INFO:Checking exceptions
2023-12-13 19:33:12,145:INFO:Importing libraries
2023-12-13 19:33:12,145:INFO:Copying training dataset
2023-12-13 19:33:12,145:INFO:Defining folds
2023-12-13 19:33:12,145:INFO:Declaring metric variables
2023-12-13 19:33:12,145:INFO:Importing untrained model
2023-12-13 19:33:12,145:INFO:Declaring custom model
2023-12-13 19:33:12,145:INFO:Gradient Boosting Classifier Imported successfully
2023-12-13 19:33:12,145:INFO:Cross validation set to False
2023-12-13 19:33:12,145:INFO:Fitting Model
2023-12-13 19:33:13,006:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4195, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-12-13 19:33:13,006:INFO:create_model() successfully completed......................................
2023-12-13 19:33:13,122:INFO:Initializing create_model()
2023-12-13 19:33:13,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:13,122:INFO:Checking exceptions
2023-12-13 19:33:13,122:INFO:Importing libraries
2023-12-13 19:33:13,122:INFO:Copying training dataset
2023-12-13 19:33:13,127:INFO:Defining folds
2023-12-13 19:33:13,127:INFO:Declaring metric variables
2023-12-13 19:33:13,127:INFO:Importing untrained model
2023-12-13 19:33:13,127:INFO:Declaring custom model
2023-12-13 19:33:13,127:INFO:Decision Tree Classifier Imported successfully
2023-12-13 19:33:13,127:INFO:Cross validation set to False
2023-12-13 19:33:13,127:INFO:Fitting Model
2023-12-13 19:33:13,127:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best')
2023-12-13 19:33:13,127:INFO:create_model() successfully completed......................................
2023-12-13 19:33:13,242:INFO:Initializing create_model()
2023-12-13 19:33:13,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4195, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-13 19:33:13,242:INFO:Checking exceptions
2023-12-13 19:33:13,251:INFO:Importing libraries
2023-12-13 19:33:13,251:INFO:Copying training dataset
2023-12-13 19:33:13,253:INFO:Defining folds
2023-12-13 19:33:13,253:INFO:Declaring metric variables
2023-12-13 19:33:13,253:INFO:Importing untrained model
2023-12-13 19:33:13,253:INFO:Declaring custom model
2023-12-13 19:33:13,255:INFO:Random Forest Classifier Imported successfully
2023-12-13 19:33:13,255:INFO:Cross validation set to False
2023-12-13 19:33:13,258:INFO:Fitting Model
2023-12-13 19:33:13,373:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4195, verbose=0, warm_start=False)
2023-12-13 19:33:13,373:INFO:create_model() successfully completed......................................
2023-12-13 19:33:13,509:INFO:_master_model_container: 30
2023-12-13 19:33:13,509:INFO:_display_container: 3
2023-12-13 19:33:13,509:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4195, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='multi:softprob', predictor=None, ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4195, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4195, verbose=0, warm_start=False)]
2023-12-13 19:33:13,509:INFO:compare_models() successfully completed......................................
2023-12-13 19:35:16,206:INFO:Initializing interpret_model()
2023-12-13 19:35:16,206:INFO:interpret_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>)
2023-12-13 19:35:16,206:INFO:Checking exceptions
2023-12-13 19:35:16,206:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-12-13 19:35:45,861:INFO:Initializing interpret_model()
2023-12-13 19:35:45,861:INFO:interpret_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>)
2023-12-13 19:35:45,861:INFO:Checking exceptions
2023-12-13 19:35:45,861:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-12-13 19:36:06,843:INFO:Initializing plot_model()
2023-12-13 19:36:06,843:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:36:06,843:INFO:Checking exceptions
2023-12-13 19:36:06,843:INFO:Preloading libraries
2023-12-13 19:36:06,843:INFO:Copying training dataset
2023-12-13 19:36:06,843:INFO:Plot type: auc
2023-12-13 19:36:06,904:INFO:Fitting Model
2023-12-13 19:36:06,904:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-12-13 19:36:06,904:INFO:Scoring test/hold-out set
2023-12-13 19:36:07,070:INFO:Visual Rendered Successfully
2023-12-13 19:36:07,186:INFO:plot_model() successfully completed......................................
2023-12-13 19:40:26,781:INFO:Initializing evaluate_model()
2023-12-13 19:40:26,781:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-12-13 19:40:26,805:INFO:Initializing plot_model()
2023-12-13 19:40:26,805:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:26,813:INFO:Checking exceptions
2023-12-13 19:40:26,813:INFO:Preloading libraries
2023-12-13 19:40:26,813:INFO:Copying training dataset
2023-12-13 19:40:26,813:INFO:Plot type: pipeline
2023-12-13 19:40:26,983:INFO:Visual Rendered Successfully
2023-12-13 19:40:27,183:INFO:plot_model() successfully completed......................................
2023-12-13 19:40:32,908:INFO:Initializing plot_model()
2023-12-13 19:40:32,908:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:32,908:INFO:Checking exceptions
2023-12-13 19:40:32,908:INFO:Preloading libraries
2023-12-13 19:40:32,908:INFO:Copying training dataset
2023-12-13 19:40:32,908:INFO:Plot type: parameter
2023-12-13 19:40:32,916:INFO:Visual Rendered Successfully
2023-12-13 19:40:33,012:INFO:plot_model() successfully completed......................................
2023-12-13 19:40:36,747:INFO:Initializing plot_model()
2023-12-13 19:40:36,747:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:36,747:INFO:Checking exceptions
2023-12-13 19:40:36,755:INFO:Preloading libraries
2023-12-13 19:40:36,755:INFO:Copying training dataset
2023-12-13 19:40:36,755:INFO:Plot type: auc
2023-12-13 19:40:36,803:INFO:Fitting Model
2023-12-13 19:40:36,803:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-12-13 19:40:36,803:INFO:Scoring test/hold-out set
2023-12-13 19:40:36,928:INFO:Visual Rendered Successfully
2023-12-13 19:40:37,022:INFO:plot_model() successfully completed......................................
2023-12-13 19:40:39,643:INFO:Initializing plot_model()
2023-12-13 19:40:39,643:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:39,643:INFO:Checking exceptions
2023-12-13 19:40:39,643:INFO:Preloading libraries
2023-12-13 19:40:39,643:INFO:Copying training dataset
2023-12-13 19:40:39,643:INFO:Plot type: confusion_matrix
2023-12-13 19:40:39,691:INFO:Fitting Model
2023-12-13 19:40:39,691:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-12-13 19:40:39,691:INFO:Scoring test/hold-out set
2023-12-13 19:40:39,787:INFO:Visual Rendered Successfully
2023-12-13 19:40:39,915:INFO:plot_model() successfully completed......................................
2023-12-13 19:40:49,161:INFO:Initializing plot_model()
2023-12-13 19:40:49,161:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:49,161:INFO:Checking exceptions
2023-12-13 19:40:51,571:INFO:Initializing plot_model()
2023-12-13 19:40:51,571:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:51,571:INFO:Checking exceptions
2023-12-13 19:40:51,571:INFO:Preloading libraries
2023-12-13 19:40:51,571:INFO:Copying training dataset
2023-12-13 19:40:51,571:INFO:Plot type: pr
2023-12-13 19:40:51,619:INFO:Fitting Model
2023-12-13 19:40:51,635:INFO:Scoring test/hold-out set
2023-12-13 19:40:51,742:INFO:Visual Rendered Successfully
2023-12-13 19:40:51,910:INFO:plot_model() successfully completed......................................
2023-12-13 19:40:53,154:INFO:Initializing plot_model()
2023-12-13 19:40:53,154:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:53,154:INFO:Checking exceptions
2023-12-13 19:40:53,154:INFO:Preloading libraries
2023-12-13 19:40:53,154:INFO:Copying training dataset
2023-12-13 19:40:53,154:INFO:Plot type: error
2023-12-13 19:40:53,202:INFO:Fitting Model
2023-12-13 19:40:53,202:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-12-13 19:40:53,202:INFO:Scoring test/hold-out set
2023-12-13 19:40:53,338:INFO:Visual Rendered Successfully
2023-12-13 19:40:53,442:INFO:plot_model() successfully completed......................................
2023-12-13 19:40:57,861:INFO:Initializing plot_model()
2023-12-13 19:40:57,861:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:57,861:INFO:Checking exceptions
2023-12-13 19:40:57,861:INFO:Preloading libraries
2023-12-13 19:40:57,861:INFO:Copying training dataset
2023-12-13 19:40:57,861:INFO:Plot type: class_report
2023-12-13 19:40:57,909:INFO:Fitting Model
2023-12-13 19:40:57,909:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-12-13 19:40:57,909:INFO:Scoring test/hold-out set
2023-12-13 19:40:58,053:INFO:Visual Rendered Successfully
2023-12-13 19:40:58,181:INFO:plot_model() successfully completed......................................
2023-12-13 19:40:59,525:INFO:Initializing plot_model()
2023-12-13 19:40:59,525:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:40:59,525:INFO:Checking exceptions
2023-12-13 19:41:04,778:INFO:Initializing plot_model()
2023-12-13 19:41:04,778:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:04,778:INFO:Checking exceptions
2023-12-13 19:41:04,778:INFO:Preloading libraries
2023-12-13 19:41:04,778:INFO:Copying training dataset
2023-12-13 19:41:04,778:INFO:Plot type: learning
2023-12-13 19:41:04,834:INFO:Fitting Model
2023-12-13 19:41:07,788:INFO:Visual Rendered Successfully
2023-12-13 19:41:07,895:INFO:plot_model() successfully completed......................................
2023-12-13 19:41:07,997:INFO:Initializing plot_model()
2023-12-13 19:41:07,997:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:07,997:INFO:Checking exceptions
2023-12-13 19:41:08,211:INFO:Initializing plot_model()
2023-12-13 19:41:08,211:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:08,211:INFO:Checking exceptions
2023-12-13 19:41:09,103:INFO:Initializing plot_model()
2023-12-13 19:41:09,103:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:09,103:INFO:Checking exceptions
2023-12-13 19:41:11,503:INFO:Initializing plot_model()
2023-12-13 19:41:11,503:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:11,503:INFO:Checking exceptions
2023-12-13 19:41:11,511:INFO:Preloading libraries
2023-12-13 19:41:11,511:INFO:Copying training dataset
2023-12-13 19:41:11,511:INFO:Plot type: learning
2023-12-13 19:41:11,551:INFO:Fitting Model
2023-12-13 19:41:11,825:INFO:Visual Rendered Successfully
2023-12-13 19:41:11,928:INFO:plot_model() successfully completed......................................
2023-12-13 19:41:12,319:INFO:Initializing plot_model()
2023-12-13 19:41:12,319:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:12,319:INFO:Checking exceptions
2023-12-13 19:41:13,346:INFO:Initializing plot_model()
2023-12-13 19:41:13,346:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:13,346:INFO:Checking exceptions
2023-12-13 19:41:13,346:INFO:Preloading libraries
2023-12-13 19:41:13,346:INFO:Copying training dataset
2023-12-13 19:41:13,346:INFO:Plot type: learning
2023-12-13 19:41:13,397:INFO:Fitting Model
2023-12-13 19:41:13,647:INFO:Visual Rendered Successfully
2023-12-13 19:41:13,740:INFO:plot_model() successfully completed......................................
2023-12-13 19:41:28,753:INFO:Initializing plot_model()
2023-12-13 19:41:28,753:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:28,753:INFO:Checking exceptions
2023-12-13 19:41:28,753:INFO:Preloading libraries
2023-12-13 19:41:28,753:INFO:Copying training dataset
2023-12-13 19:41:28,753:INFO:Plot type: boundary
2023-12-13 19:41:28,777:INFO:Fitting StandardScaler()
2023-12-13 19:41:28,785:INFO:Fitting PCA()
2023-12-13 19:41:28,817:INFO:Fitting Model
2023-12-13 19:41:29,572:INFO:Visual Rendered Successfully
2023-12-13 19:41:29,762:INFO:plot_model() successfully completed......................................
2023-12-13 19:41:29,778:INFO:Initializing plot_model()
2023-12-13 19:41:29,778:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:29,778:INFO:Checking exceptions
2023-12-13 19:41:30,803:INFO:Initializing plot_model()
2023-12-13 19:41:30,803:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:30,803:INFO:Checking exceptions
2023-12-13 19:41:33,286:INFO:Initializing plot_model()
2023-12-13 19:41:33,286:INFO:plot_model(plot=vc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:41:33,286:INFO:Checking exceptions
2023-12-13 19:41:33,286:INFO:Preloading libraries
2023-12-13 19:41:33,286:INFO:Copying training dataset
2023-12-13 19:41:33,286:INFO:Plot type: vc
2023-12-13 19:41:33,286:INFO:Determining param_name
2023-12-13 19:41:33,286:INFO:param_name: max_depth
2023-12-13 19:41:33,334:INFO:Fitting Model
2023-12-13 19:41:33,600:INFO:Visual Rendered Successfully
2023-12-13 19:41:33,709:INFO:plot_model() successfully completed......................................
2023-12-13 19:42:01,112:INFO:Initializing plot_model()
2023-12-13 19:42:01,112:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:42:01,112:INFO:Checking exceptions
2023-12-13 19:42:01,112:INFO:Preloading libraries
2023-12-13 19:42:01,112:INFO:Copying training dataset
2023-12-13 19:42:01,112:INFO:Plot type: dimension
2023-12-13 19:42:01,152:INFO:Fitting StandardScaler()
2023-12-13 19:42:01,163:INFO:Fitting PCA()
2023-12-13 19:42:01,210:INFO:Fitting & Transforming Model
2023-12-13 19:42:01,397:INFO:Visual Rendered Successfully
2023-12-13 19:42:01,530:INFO:plot_model() successfully completed......................................
2023-12-13 19:42:03,296:INFO:Initializing plot_model()
2023-12-13 19:42:03,296:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:42:03,296:INFO:Checking exceptions
2023-12-13 19:42:03,296:INFO:Preloading libraries
2023-12-13 19:42:03,296:INFO:Copying training dataset
2023-12-13 19:42:03,296:INFO:Plot type: feature
2023-12-13 19:42:03,296:WARNING:No coef_ found. Trying feature_importances_
2023-12-13 19:42:03,393:INFO:Visual Rendered Successfully
2023-12-13 19:42:03,502:INFO:plot_model() successfully completed......................................
2023-12-13 19:42:25,454:INFO:Initializing plot_model()
2023-12-13 19:42:25,454:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:42:25,454:INFO:Checking exceptions
2023-12-13 19:42:25,454:INFO:Preloading libraries
2023-12-13 19:42:25,454:INFO:Copying training dataset
2023-12-13 19:42:25,454:INFO:Plot type: feature_all
2023-12-13 19:42:25,470:WARNING:No coef_ found. Trying feature_importances_
2023-12-13 19:42:25,534:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2023-12-13 19:42:25,534:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2023-12-13 19:42:25,534:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\matplotlib\patches.py:737: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2023-12-13 19:42:25,534:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\matplotlib\transforms.py:2047: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2023-12-13 19:42:25,565:INFO:Visual Rendered Successfully
2023-12-13 19:42:25,659:INFO:plot_model() successfully completed......................................
2023-12-13 19:42:27,366:INFO:Initializing plot_model()
2023-12-13 19:42:27,366:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:42:27,366:INFO:Checking exceptions
2023-12-13 19:42:27,366:INFO:Preloading libraries
2023-12-13 19:42:27,366:INFO:Copying training dataset
2023-12-13 19:42:27,366:INFO:Plot type: boundary
2023-12-13 19:42:27,390:INFO:Fitting StandardScaler()
2023-12-13 19:42:27,399:INFO:Fitting PCA()
2023-12-13 19:42:27,431:INFO:Fitting Model
2023-12-13 19:42:28,168:INFO:Visual Rendered Successfully
2023-12-13 19:42:28,385:INFO:plot_model() successfully completed......................................
2023-12-13 19:42:30,379:INFO:Initializing plot_model()
2023-12-13 19:42:30,379:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:42:30,379:INFO:Checking exceptions
2023-12-13 19:42:30,379:INFO:Preloading libraries
2023-12-13 19:42:30,379:INFO:Copying training dataset
2023-12-13 19:42:30,379:INFO:Plot type: lift
2023-12-13 19:42:30,379:INFO:Generating predictions / predict_proba on X_test
2023-12-13 19:42:32,486:INFO:Initializing plot_model()
2023-12-13 19:42:32,486:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:42:32,486:INFO:Checking exceptions
2023-12-13 19:42:32,486:INFO:Preloading libraries
2023-12-13 19:42:32,486:INFO:Copying training dataset
2023-12-13 19:42:32,486:INFO:Plot type: gain
2023-12-13 19:42:32,486:INFO:Generating predictions / predict_proba on X_test
2023-12-13 19:42:34,201:INFO:Initializing plot_model()
2023-12-13 19:42:34,201:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:42:34,201:INFO:Checking exceptions
2023-12-13 19:42:34,201:INFO:Preloading libraries
2023-12-13 19:42:34,201:INFO:Copying training dataset
2023-12-13 19:42:34,201:INFO:Plot type: tree
2023-12-13 19:42:34,209:INFO:Plotting decision trees
2023-12-13 19:42:38,405:INFO:Initializing plot_model()
2023-12-13 19:42:38,405:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4195, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218B1364970>, system=True)
2023-12-13 19:42:38,405:INFO:Checking exceptions
2023-12-13 19:42:38,405:INFO:Preloading libraries
2023-12-13 19:42:38,405:INFO:Copying training dataset
2023-12-13 19:42:38,405:INFO:Plot type: ks
2023-12-13 19:42:38,405:INFO:Generating predictions / predict_proba on X_test
2023-12-17 22:32:48,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-17 22:32:48,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-17 22:32:48,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-17 22:32:48,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-17 22:32:50,484:INFO:PyCaret ClassificationExperiment
2023-12-17 22:32:50,484:INFO:Logging name: clf-default-name
2023-12-17 22:32:50,484:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-12-17 22:32:50,484:INFO:version 3.2.0
2023-12-17 22:32:50,484:INFO:Initializing setup()
2023-12-17 22:32:50,484:INFO:self.USI: 7b45
2023-12-17 22:32:50,484:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'html_param', 'X_test', '_available_plots', 'target_param', 'is_multiclass', 'y', 'gpu_n_jobs_param', 'pipeline', 'USI', 'n_jobs_param', 'y_train', 'data', 'memory', 'gpu_param', 'fold_generator', 'idx', 'logging_param', '_ml_usecase', 'log_plots_param', 'y_test', 'X', 'X_train', 'fold_shuffle_param', 'fold_groups_param', 'exp_name_log', 'seed'}
2023-12-17 22:32:50,484:INFO:Checking environment
2023-12-17 22:32:50,484:INFO:python_version: 3.10.6
2023-12-17 22:32:50,484:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-12-17 22:32:50,484:INFO:machine: AMD64
2023-12-17 22:32:50,485:INFO:platform: Windows-10-10.0.19045-SP0
2023-12-17 22:32:50,485:INFO:Memory: svmem(total=21264392192, available=7821025280, percent=63.2, used=13443366912, free=7821025280)
2023-12-17 22:32:50,485:INFO:Physical Core: 4
2023-12-17 22:32:50,485:INFO:Logical Core: 8
2023-12-17 22:32:50,485:INFO:Checking libraries
2023-12-17 22:32:50,485:INFO:System:
2023-12-17 22:32:50,485:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-12-17 22:32:50,485:INFO:executable: c:\Users\lenovo\AppData\Local\Programs\Python\Python310\python.exe
2023-12-17 22:32:50,485:INFO:   machine: Windows-10-10.0.19045-SP0
2023-12-17 22:32:50,485:INFO:PyCaret required dependencies:
2023-12-17 22:32:50,601:INFO:                 pip: 23.3.1
2023-12-17 22:32:50,601:INFO:          setuptools: 63.2.0
2023-12-17 22:32:50,601:INFO:             pycaret: 3.2.0
2023-12-17 22:32:50,601:INFO:             IPython: 8.4.0
2023-12-17 22:32:50,601:INFO:          ipywidgets: 8.1.1
2023-12-17 22:32:50,601:INFO:                tqdm: 4.65.0
2023-12-17 22:32:50,602:INFO:               numpy: 1.24.4
2023-12-17 22:32:50,602:INFO:              pandas: 1.4.3
2023-12-17 22:32:50,602:INFO:              jinja2: 3.1.2
2023-12-17 22:32:50,602:INFO:               scipy: 1.10.1
2023-12-17 22:32:50,602:INFO:              joblib: 1.2.0
2023-12-17 22:32:50,602:INFO:             sklearn: 1.0.2
2023-12-17 22:32:50,602:INFO:                pyod: 1.1.2
2023-12-17 22:32:50,602:INFO:            imblearn: 0.10.1
2023-12-17 22:32:50,602:INFO:   category_encoders: 2.6.3
2023-12-17 22:32:50,602:INFO:            lightgbm: 4.1.0
2023-12-17 22:32:50,602:INFO:               numba: 0.58.1
2023-12-17 22:32:50,602:INFO:            requests: 2.28.1
2023-12-17 22:32:50,602:INFO:          matplotlib: 3.8.2
2023-12-17 22:32:50,602:INFO:          scikitplot: 0.3.7
2023-12-17 22:32:50,602:INFO:         yellowbrick: 1.5
2023-12-17 22:32:50,602:INFO:              plotly: 5.10.0
2023-12-17 22:32:50,602:INFO:    plotly-resampler: Not installed
2023-12-17 22:32:50,602:INFO:             kaleido: 0.2.1
2023-12-17 22:32:50,602:INFO:           schemdraw: 0.15
2023-12-17 22:32:50,602:INFO:         statsmodels: 0.14.0
2023-12-17 22:32:50,602:INFO:              sktime: 0.21.1
2023-12-17 22:32:50,602:INFO:               tbats: 1.1.3
2023-12-17 22:32:50,602:INFO:            pmdarima: 2.0.4
2023-12-17 22:32:50,602:INFO:              psutil: 5.9.1
2023-12-17 22:32:50,602:INFO:          markupsafe: 2.1.1
2023-12-17 22:32:50,602:INFO:             pickle5: Not installed
2023-12-17 22:32:50,602:INFO:         cloudpickle: 3.0.0
2023-12-17 22:32:50,602:INFO:         deprecation: 2.1.0
2023-12-17 22:32:50,602:INFO:              xxhash: 3.4.1
2023-12-17 22:32:50,602:INFO:           wurlitzer: Not installed
2023-12-17 22:32:50,602:INFO:PyCaret optional dependencies:
2023-12-17 22:32:50,612:INFO:                shap: Not installed
2023-12-17 22:32:50,612:INFO:           interpret: Not installed
2023-12-17 22:32:50,612:INFO:                umap: Not installed
2023-12-17 22:32:50,612:INFO:     ydata_profiling: Not installed
2023-12-17 22:32:50,612:INFO:  explainerdashboard: Not installed
2023-12-17 22:32:50,612:INFO:             autoviz: Not installed
2023-12-17 22:32:50,612:INFO:           fairlearn: Not installed
2023-12-17 22:32:50,612:INFO:          deepchecks: Not installed
2023-12-17 22:32:50,612:INFO:             xgboost: 1.7.3
2023-12-17 22:32:50,612:INFO:            catboost: Not installed
2023-12-17 22:32:50,612:INFO:              kmodes: Not installed
2023-12-17 22:32:50,612:INFO:             mlxtend: Not installed
2023-12-17 22:32:50,612:INFO:       statsforecast: Not installed
2023-12-17 22:32:50,612:INFO:        tune_sklearn: Not installed
2023-12-17 22:32:50,612:INFO:                 ray: Not installed
2023-12-17 22:32:50,612:INFO:            hyperopt: Not installed
2023-12-17 22:32:50,612:INFO:              optuna: Not installed
2023-12-17 22:32:50,612:INFO:               skopt: Not installed
2023-12-17 22:32:50,612:INFO:              mlflow: Not installed
2023-12-17 22:32:50,613:INFO:              gradio: Not installed
2023-12-17 22:32:50,613:INFO:             fastapi: Not installed
2023-12-17 22:32:50,613:INFO:             uvicorn: Not installed
2023-12-17 22:32:50,613:INFO:              m2cgen: Not installed
2023-12-17 22:32:50,613:INFO:           evidently: Not installed
2023-12-17 22:32:50,613:INFO:               fugue: Not installed
2023-12-17 22:32:50,613:INFO:           streamlit: 1.27.2
2023-12-17 22:32:50,613:INFO:             prophet: Not installed
2023-12-17 22:32:50,613:INFO:None
2023-12-17 22:32:50,613:INFO:Set up data.
2023-12-17 22:32:50,621:INFO:Set up folding strategy.
2023-12-17 22:32:50,621:INFO:Set up train/test split.
2023-12-17 22:32:50,625:INFO:Set up index.
2023-12-17 22:32:50,625:INFO:Assigning column types.
2023-12-17 22:32:50,628:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-12-17 22:32:50,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-17 22:32:50,681:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-17 22:32:50,719:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-17 22:32:50,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-17 22:32:50,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-17 22:32:50,888:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-17 22:32:50,916:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-17 22:32:50,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-17 22:32:50,919:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-12-17 22:32:50,962:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-17 22:32:50,989:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-17 22:32:50,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-17 22:32:51,035:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-17 22:32:51,061:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-17 22:32:51,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-17 22:32:51,066:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-12-17 22:32:51,142:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-17 22:32:51,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-17 22:32:51,217:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-17 22:32:51,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-17 22:32:51,221:INFO:Preparing preprocessing pipeline...
2023-12-17 22:32:51,225:INFO:Set up simple imputation.
2023-12-17 22:32:51,225:INFO:Set up column name cleaning.
2023-12-17 22:32:51,261:INFO:Finished creating preprocessing pipeline.
2023-12-17 22:32:51,268:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Date', 'CarCount', 'BikeCount',
                                             'BusCount', 'TruckCount', 'Total',
                                             'Day', 'Daytime', 'MonthQuarter'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              v...se=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-12-17 22:32:51,268:INFO:Creating final display dataframe.
2023-12-17 22:32:51,354:INFO:Setup _display_container:                     Description              Value
0                    Session id               8629
1                        Target  Traffic Situation
2                   Target type         Multiclass
3           Original data shape         (2976, 10)
4        Transformed data shape         (2976, 10)
5   Transformed train set shape         (2083, 10)
6    Transformed test set shape          (893, 10)
7              Numeric features                  9
8                    Preprocess               True
9               Imputation type             simple
10           Numeric imputation               mean
11       Categorical imputation               mode
12               Fold Generator    StratifiedKFold
13                  Fold Number                 10
14                     CPU Jobs                 -1
15                      Use GPU              False
16               Log Experiment              False
17              Experiment Name   clf-default-name
18                          USI               7b45
2023-12-17 22:32:51,435:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-17 22:32:51,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-17 22:32:51,504:INFO:Soft dependency imported: xgboost: 1.7.3
2023-12-17 22:32:51,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-17 22:32:51,506:INFO:setup() successfully completed in 1.03s...............
2023-12-17 22:32:51,528:INFO:Initializing compare_models()
2023-12-17 22:32:51,528:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-12-17 22:32:51,529:INFO:Checking exceptions
2023-12-17 22:32:51,535:INFO:Preparing display monitor
2023-12-17 22:32:51,590:INFO:Initializing Logistic Regression
2023-12-17 22:32:51,591:INFO:Total runtime is 1.6379356384277344e-05 minutes
2023-12-17 22:32:51,600:INFO:SubProcess create_model() called ==================================
2023-12-17 22:32:51,601:INFO:Initializing create_model()
2023-12-17 22:32:51,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:32:51,601:INFO:Checking exceptions
2023-12-17 22:32:51,601:INFO:Importing libraries
2023-12-17 22:32:51,602:INFO:Copying training dataset
2023-12-17 22:32:51,609:INFO:Defining folds
2023-12-17 22:32:51,609:INFO:Declaring metric variables
2023-12-17 22:32:51,613:INFO:Importing untrained model
2023-12-17 22:32:51,620:INFO:Logistic Regression Imported successfully
2023-12-17 22:32:51,632:INFO:Starting cross validation
2023-12-17 22:32:51,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:01,292:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:01,367:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:01,385:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:01,391:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:01,420:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:01,423:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:01,567:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:01,604:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:02,366:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:02,423:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-12-17 22:33:02,436:INFO:Calculating mean and std
2023-12-17 22:33:02,438:INFO:Creating metrics dataframe
2023-12-17 22:33:02,445:INFO:Uploading results into container
2023-12-17 22:33:02,445:INFO:Uploading model into container now
2023-12-17 22:33:02,446:INFO:_master_model_container: 1
2023-12-17 22:33:02,446:INFO:_display_container: 2
2023-12-17 22:33:02,447:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8629, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-12-17 22:33:02,447:INFO:create_model() successfully completed......................................
2023-12-17 22:33:02,533:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:02,534:INFO:Creating metrics dataframe
2023-12-17 22:33:02,541:INFO:Initializing K Neighbors Classifier
2023-12-17 22:33:02,542:INFO:Total runtime is 0.1825409650802612 minutes
2023-12-17 22:33:02,544:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:02,545:INFO:Initializing create_model()
2023-12-17 22:33:02,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:02,545:INFO:Checking exceptions
2023-12-17 22:33:02,545:INFO:Importing libraries
2023-12-17 22:33:02,546:INFO:Copying training dataset
2023-12-17 22:33:02,552:INFO:Defining folds
2023-12-17 22:33:02,552:INFO:Declaring metric variables
2023-12-17 22:33:02,556:INFO:Importing untrained model
2023-12-17 22:33:02,561:INFO:K Neighbors Classifier Imported successfully
2023-12-17 22:33:02,569:INFO:Starting cross validation
2023-12-17 22:33:02,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-17 22:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-17 22:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-17 22:33:02,641:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-17 22:33:02,647:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-17 22:33:02,711:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-17 22:33:02,711:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-12-17 22:33:02,733:INFO:Calculating mean and std
2023-12-17 22:33:02,734:INFO:Creating metrics dataframe
2023-12-17 22:33:02,736:INFO:Uploading results into container
2023-12-17 22:33:02,737:INFO:Uploading model into container now
2023-12-17 22:33:02,737:INFO:_master_model_container: 2
2023-12-17 22:33:02,738:INFO:_display_container: 2
2023-12-17 22:33:02,738:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-12-17 22:33:02,738:INFO:create_model() successfully completed......................................
2023-12-17 22:33:02,826:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:02,826:INFO:Creating metrics dataframe
2023-12-17 22:33:02,835:INFO:Initializing Naive Bayes
2023-12-17 22:33:02,835:INFO:Total runtime is 0.18741037448247272 minutes
2023-12-17 22:33:02,839:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:02,839:INFO:Initializing create_model()
2023-12-17 22:33:02,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:02,839:INFO:Checking exceptions
2023-12-17 22:33:02,839:INFO:Importing libraries
2023-12-17 22:33:02,840:INFO:Copying training dataset
2023-12-17 22:33:02,845:INFO:Defining folds
2023-12-17 22:33:02,845:INFO:Declaring metric variables
2023-12-17 22:33:02,849:INFO:Importing untrained model
2023-12-17 22:33:02,854:INFO:Naive Bayes Imported successfully
2023-12-17 22:33:02,863:INFO:Starting cross validation
2023-12-17 22:33:02,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:02,955:INFO:Calculating mean and std
2023-12-17 22:33:02,956:INFO:Creating metrics dataframe
2023-12-17 22:33:02,959:INFO:Uploading results into container
2023-12-17 22:33:02,960:INFO:Uploading model into container now
2023-12-17 22:33:02,960:INFO:_master_model_container: 3
2023-12-17 22:33:02,960:INFO:_display_container: 2
2023-12-17 22:33:02,961:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-12-17 22:33:02,961:INFO:create_model() successfully completed......................................
2023-12-17 22:33:03,043:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:03,043:INFO:Creating metrics dataframe
2023-12-17 22:33:03,055:INFO:Initializing Decision Tree Classifier
2023-12-17 22:33:03,055:INFO:Total runtime is 0.1910868446032206 minutes
2023-12-17 22:33:03,059:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:03,059:INFO:Initializing create_model()
2023-12-17 22:33:03,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:03,059:INFO:Checking exceptions
2023-12-17 22:33:03,059:INFO:Importing libraries
2023-12-17 22:33:03,059:INFO:Copying training dataset
2023-12-17 22:33:03,067:INFO:Defining folds
2023-12-17 22:33:03,067:INFO:Declaring metric variables
2023-12-17 22:33:03,071:INFO:Importing untrained model
2023-12-17 22:33:03,074:INFO:Decision Tree Classifier Imported successfully
2023-12-17 22:33:03,080:INFO:Starting cross validation
2023-12-17 22:33:03,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:03,178:INFO:Calculating mean and std
2023-12-17 22:33:03,180:INFO:Creating metrics dataframe
2023-12-17 22:33:03,185:INFO:Uploading results into container
2023-12-17 22:33:03,185:INFO:Uploading model into container now
2023-12-17 22:33:03,185:INFO:_master_model_container: 4
2023-12-17 22:33:03,186:INFO:_display_container: 2
2023-12-17 22:33:03,186:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8629, splitter='best')
2023-12-17 22:33:03,186:INFO:create_model() successfully completed......................................
2023-12-17 22:33:03,299:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:03,300:INFO:Creating metrics dataframe
2023-12-17 22:33:03,314:INFO:Initializing SVM - Linear Kernel
2023-12-17 22:33:03,314:INFO:Total runtime is 0.1954060872395833 minutes
2023-12-17 22:33:03,321:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:03,321:INFO:Initializing create_model()
2023-12-17 22:33:03,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:03,321:INFO:Checking exceptions
2023-12-17 22:33:03,322:INFO:Importing libraries
2023-12-17 22:33:03,322:INFO:Copying training dataset
2023-12-17 22:33:03,327:INFO:Defining folds
2023-12-17 22:33:03,328:INFO:Declaring metric variables
2023-12-17 22:33:03,332:INFO:Importing untrained model
2023-12-17 22:33:03,339:INFO:SVM - Linear Kernel Imported successfully
2023-12-17 22:33:03,350:INFO:Starting cross validation
2023-12-17 22:33:03,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:03,543:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-17 22:33:03,543:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-17 22:33:03,543:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-17 22:33:03,562:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,562:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,603:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-17 22:33:03,605:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-17 22:33:03,611:INFO:Calculating mean and std
2023-12-17 22:33:03,612:INFO:Creating metrics dataframe
2023-12-17 22:33:03,617:INFO:Uploading results into container
2023-12-17 22:33:03,618:INFO:Uploading model into container now
2023-12-17 22:33:03,618:INFO:_master_model_container: 5
2023-12-17 22:33:03,618:INFO:_display_container: 2
2023-12-17 22:33:03,619:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8629, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-12-17 22:33:03,619:INFO:create_model() successfully completed......................................
2023-12-17 22:33:03,704:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:03,704:INFO:Creating metrics dataframe
2023-12-17 22:33:03,716:INFO:Initializing Ridge Classifier
2023-12-17 22:33:03,716:INFO:Total runtime is 0.2020947416623433 minutes
2023-12-17 22:33:03,720:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:03,720:INFO:Initializing create_model()
2023-12-17 22:33:03,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:03,721:INFO:Checking exceptions
2023-12-17 22:33:03,721:INFO:Importing libraries
2023-12-17 22:33:03,721:INFO:Copying training dataset
2023-12-17 22:33:03,725:INFO:Defining folds
2023-12-17 22:33:03,725:INFO:Declaring metric variables
2023-12-17 22:33:03,729:INFO:Importing untrained model
2023-12-17 22:33:03,733:INFO:Ridge Classifier Imported successfully
2023-12-17 22:33:03,739:INFO:Starting cross validation
2023-12-17 22:33:03,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:03,791:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,791:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,791:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,792:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,793:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,793:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,794:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,795:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,796:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,796:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,799:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,799:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,800:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,800:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,802:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,802:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,821:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,823:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-17 22:33:03,824:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,826:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:03,829:INFO:Calculating mean and std
2023-12-17 22:33:03,830:INFO:Creating metrics dataframe
2023-12-17 22:33:03,833:INFO:Uploading results into container
2023-12-17 22:33:03,833:INFO:Uploading model into container now
2023-12-17 22:33:03,833:INFO:_master_model_container: 6
2023-12-17 22:33:03,834:INFO:_display_container: 2
2023-12-17 22:33:03,834:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=8629, solver='auto', tol=0.001)
2023-12-17 22:33:03,834:INFO:create_model() successfully completed......................................
2023-12-17 22:33:03,922:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:03,922:INFO:Creating metrics dataframe
2023-12-17 22:33:03,932:INFO:Initializing Random Forest Classifier
2023-12-17 22:33:03,932:INFO:Total runtime is 0.20570780436197914 minutes
2023-12-17 22:33:03,935:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:03,936:INFO:Initializing create_model()
2023-12-17 22:33:03,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:03,936:INFO:Checking exceptions
2023-12-17 22:33:03,936:INFO:Importing libraries
2023-12-17 22:33:03,936:INFO:Copying training dataset
2023-12-17 22:33:03,941:INFO:Defining folds
2023-12-17 22:33:03,941:INFO:Declaring metric variables
2023-12-17 22:33:03,945:INFO:Importing untrained model
2023-12-17 22:33:03,950:INFO:Random Forest Classifier Imported successfully
2023-12-17 22:33:03,957:INFO:Starting cross validation
2023-12-17 22:33:03,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:04,894:INFO:Calculating mean and std
2023-12-17 22:33:04,896:INFO:Creating metrics dataframe
2023-12-17 22:33:04,901:INFO:Uploading results into container
2023-12-17 22:33:04,902:INFO:Uploading model into container now
2023-12-17 22:33:04,902:INFO:_master_model_container: 7
2023-12-17 22:33:04,903:INFO:_display_container: 2
2023-12-17 22:33:04,903:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8629, verbose=0, warm_start=False)
2023-12-17 22:33:04,903:INFO:create_model() successfully completed......................................
2023-12-17 22:33:05,001:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:05,001:INFO:Creating metrics dataframe
2023-12-17 22:33:05,018:INFO:Initializing Quadratic Discriminant Analysis
2023-12-17 22:33:05,018:INFO:Total runtime is 0.2237926125526428 minutes
2023-12-17 22:33:05,022:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:05,023:INFO:Initializing create_model()
2023-12-17 22:33:05,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:05,023:INFO:Checking exceptions
2023-12-17 22:33:05,024:INFO:Importing libraries
2023-12-17 22:33:05,024:INFO:Copying training dataset
2023-12-17 22:33:05,032:INFO:Defining folds
2023-12-17 22:33:05,032:INFO:Declaring metric variables
2023-12-17 22:33:05,037:INFO:Importing untrained model
2023-12-17 22:33:05,072:INFO:Quadratic Discriminant Analysis Imported successfully
2023-12-17 22:33:05,091:INFO:Starting cross validation
2023-12-17 22:33:05,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:05,164:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-17 22:33:05,165:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-17 22:33:05,165:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-17 22:33:05,182:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-17 22:33:05,211:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-17 22:33:05,213:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-17 22:33:05,233:INFO:Calculating mean and std
2023-12-17 22:33:05,235:INFO:Creating metrics dataframe
2023-12-17 22:33:05,239:INFO:Uploading results into container
2023-12-17 22:33:05,240:INFO:Uploading model into container now
2023-12-17 22:33:05,240:INFO:_master_model_container: 8
2023-12-17 22:33:05,240:INFO:_display_container: 2
2023-12-17 22:33:05,241:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-12-17 22:33:05,241:INFO:create_model() successfully completed......................................
2023-12-17 22:33:05,347:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:05,347:INFO:Creating metrics dataframe
2023-12-17 22:33:05,362:INFO:Initializing Ada Boost Classifier
2023-12-17 22:33:05,362:INFO:Total runtime is 0.2295314868291219 minutes
2023-12-17 22:33:05,369:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:05,370:INFO:Initializing create_model()
2023-12-17 22:33:05,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:05,370:INFO:Checking exceptions
2023-12-17 22:33:05,370:INFO:Importing libraries
2023-12-17 22:33:05,370:INFO:Copying training dataset
2023-12-17 22:33:05,376:INFO:Defining folds
2023-12-17 22:33:05,376:INFO:Declaring metric variables
2023-12-17 22:33:05,381:INFO:Importing untrained model
2023-12-17 22:33:05,388:INFO:Ada Boost Classifier Imported successfully
2023-12-17 22:33:05,396:INFO:Starting cross validation
2023-12-17 22:33:05,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:05,763:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,767:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,771:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,775:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,781:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,800:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,801:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,803:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,977:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,983:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:05,986:INFO:Calculating mean and std
2023-12-17 22:33:05,988:INFO:Creating metrics dataframe
2023-12-17 22:33:05,991:INFO:Uploading results into container
2023-12-17 22:33:05,991:INFO:Uploading model into container now
2023-12-17 22:33:05,992:INFO:_master_model_container: 9
2023-12-17 22:33:05,992:INFO:_display_container: 2
2023-12-17 22:33:05,992:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8629)
2023-12-17 22:33:05,992:INFO:create_model() successfully completed......................................
2023-12-17 22:33:06,082:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:06,083:INFO:Creating metrics dataframe
2023-12-17 22:33:06,093:INFO:Initializing Gradient Boosting Classifier
2023-12-17 22:33:06,093:INFO:Total runtime is 0.24171630938847857 minutes
2023-12-17 22:33:06,099:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:06,100:INFO:Initializing create_model()
2023-12-17 22:33:06,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:06,100:INFO:Checking exceptions
2023-12-17 22:33:06,100:INFO:Importing libraries
2023-12-17 22:33:06,100:INFO:Copying training dataset
2023-12-17 22:33:06,106:INFO:Defining folds
2023-12-17 22:33:06,106:INFO:Declaring metric variables
2023-12-17 22:33:06,109:INFO:Importing untrained model
2023-12-17 22:33:06,114:INFO:Gradient Boosting Classifier Imported successfully
2023-12-17 22:33:06,123:INFO:Starting cross validation
2023-12-17 22:33:06,124:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:09,751:INFO:Calculating mean and std
2023-12-17 22:33:09,752:INFO:Creating metrics dataframe
2023-12-17 22:33:09,755:INFO:Uploading results into container
2023-12-17 22:33:09,755:INFO:Uploading model into container now
2023-12-17 22:33:09,756:INFO:_master_model_container: 10
2023-12-17 22:33:09,756:INFO:_display_container: 2
2023-12-17 22:33:09,756:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8629, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-12-17 22:33:09,756:INFO:create_model() successfully completed......................................
2023-12-17 22:33:09,848:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:09,848:INFO:Creating metrics dataframe
2023-12-17 22:33:09,859:INFO:Initializing Linear Discriminant Analysis
2023-12-17 22:33:09,859:INFO:Total runtime is 0.3044834017753601 minutes
2023-12-17 22:33:09,863:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:09,863:INFO:Initializing create_model()
2023-12-17 22:33:09,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:09,864:INFO:Checking exceptions
2023-12-17 22:33:09,864:INFO:Importing libraries
2023-12-17 22:33:09,864:INFO:Copying training dataset
2023-12-17 22:33:09,870:INFO:Defining folds
2023-12-17 22:33:09,870:INFO:Declaring metric variables
2023-12-17 22:33:09,873:INFO:Importing untrained model
2023-12-17 22:33:09,878:INFO:Linear Discriminant Analysis Imported successfully
2023-12-17 22:33:09,885:INFO:Starting cross validation
2023-12-17 22:33:09,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:09,973:INFO:Calculating mean and std
2023-12-17 22:33:09,974:INFO:Creating metrics dataframe
2023-12-17 22:33:09,978:INFO:Uploading results into container
2023-12-17 22:33:09,978:INFO:Uploading model into container now
2023-12-17 22:33:09,979:INFO:_master_model_container: 11
2023-12-17 22:33:09,979:INFO:_display_container: 2
2023-12-17 22:33:09,979:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-12-17 22:33:09,979:INFO:create_model() successfully completed......................................
2023-12-17 22:33:10,062:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:10,062:INFO:Creating metrics dataframe
2023-12-17 22:33:10,076:INFO:Initializing Extra Trees Classifier
2023-12-17 22:33:10,076:INFO:Total runtime is 0.3080932299296061 minutes
2023-12-17 22:33:10,079:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:10,079:INFO:Initializing create_model()
2023-12-17 22:33:10,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:10,079:INFO:Checking exceptions
2023-12-17 22:33:10,079:INFO:Importing libraries
2023-12-17 22:33:10,080:INFO:Copying training dataset
2023-12-17 22:33:10,088:INFO:Defining folds
2023-12-17 22:33:10,088:INFO:Declaring metric variables
2023-12-17 22:33:10,091:INFO:Importing untrained model
2023-12-17 22:33:10,095:INFO:Extra Trees Classifier Imported successfully
2023-12-17 22:33:10,103:INFO:Starting cross validation
2023-12-17 22:33:10,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:10,887:INFO:Calculating mean and std
2023-12-17 22:33:10,889:INFO:Creating metrics dataframe
2023-12-17 22:33:10,892:INFO:Uploading results into container
2023-12-17 22:33:10,892:INFO:Uploading model into container now
2023-12-17 22:33:10,893:INFO:_master_model_container: 12
2023-12-17 22:33:10,893:INFO:_display_container: 2
2023-12-17 22:33:10,894:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8629, verbose=0, warm_start=False)
2023-12-17 22:33:10,894:INFO:create_model() successfully completed......................................
2023-12-17 22:33:10,980:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:10,981:INFO:Creating metrics dataframe
2023-12-17 22:33:10,993:INFO:Initializing Extreme Gradient Boosting
2023-12-17 22:33:10,993:INFO:Total runtime is 0.32338161468505855 minutes
2023-12-17 22:33:10,997:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:10,997:INFO:Initializing create_model()
2023-12-17 22:33:10,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:10,998:INFO:Checking exceptions
2023-12-17 22:33:10,998:INFO:Importing libraries
2023-12-17 22:33:10,998:INFO:Copying training dataset
2023-12-17 22:33:11,005:INFO:Defining folds
2023-12-17 22:33:11,005:INFO:Declaring metric variables
2023-12-17 22:33:11,009:INFO:Importing untrained model
2023-12-17 22:33:11,014:INFO:Extreme Gradient Boosting Imported successfully
2023-12-17 22:33:11,022:INFO:Starting cross validation
2023-12-17 22:33:11,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:11,991:INFO:Calculating mean and std
2023-12-17 22:33:11,993:INFO:Creating metrics dataframe
2023-12-17 22:33:11,997:INFO:Uploading results into container
2023-12-17 22:33:11,999:INFO:Uploading model into container now
2023-12-17 22:33:12,000:INFO:_master_model_container: 13
2023-12-17 22:33:12,000:INFO:_display_container: 2
2023-12-17 22:33:12,001:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-12-17 22:33:12,001:INFO:create_model() successfully completed......................................
2023-12-17 22:33:12,128:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:12,129:INFO:Creating metrics dataframe
2023-12-17 22:33:12,142:INFO:Initializing Light Gradient Boosting Machine
2023-12-17 22:33:12,142:INFO:Total runtime is 0.3425334970156351 minutes
2023-12-17 22:33:12,146:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:12,147:INFO:Initializing create_model()
2023-12-17 22:33:12,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:12,147:INFO:Checking exceptions
2023-12-17 22:33:12,147:INFO:Importing libraries
2023-12-17 22:33:12,147:INFO:Copying training dataset
2023-12-17 22:33:12,153:INFO:Defining folds
2023-12-17 22:33:12,153:INFO:Declaring metric variables
2023-12-17 22:33:12,157:INFO:Importing untrained model
2023-12-17 22:33:12,160:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-17 22:33:12,170:INFO:Starting cross validation
2023-12-17 22:33:12,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:15,188:INFO:Calculating mean and std
2023-12-17 22:33:15,190:INFO:Creating metrics dataframe
2023-12-17 22:33:15,195:INFO:Uploading results into container
2023-12-17 22:33:15,196:INFO:Uploading model into container now
2023-12-17 22:33:15,198:INFO:_master_model_container: 14
2023-12-17 22:33:15,198:INFO:_display_container: 2
2023-12-17 22:33:15,199:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8629, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-17 22:33:15,199:INFO:create_model() successfully completed......................................
2023-12-17 22:33:15,318:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:15,318:INFO:Creating metrics dataframe
2023-12-17 22:33:15,332:INFO:Initializing Dummy Classifier
2023-12-17 22:33:15,332:INFO:Total runtime is 0.39570757945378615 minutes
2023-12-17 22:33:15,336:INFO:SubProcess create_model() called ==================================
2023-12-17 22:33:15,336:INFO:Initializing create_model()
2023-12-17 22:33:15,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC260D0E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:15,337:INFO:Checking exceptions
2023-12-17 22:33:15,337:INFO:Importing libraries
2023-12-17 22:33:15,337:INFO:Copying training dataset
2023-12-17 22:33:15,343:INFO:Defining folds
2023-12-17 22:33:15,343:INFO:Declaring metric variables
2023-12-17 22:33:15,351:INFO:Importing untrained model
2023-12-17 22:33:15,357:INFO:Dummy Classifier Imported successfully
2023-12-17 22:33:15,369:INFO:Starting cross validation
2023-12-17 22:33:15,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-17 22:33:15,413:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,415:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,418:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,420:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,424:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,424:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,427:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,438:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,455:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,456:WARNING:c:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-17 22:33:15,459:INFO:Calculating mean and std
2023-12-17 22:33:15,461:INFO:Creating metrics dataframe
2023-12-17 22:33:15,466:INFO:Uploading results into container
2023-12-17 22:33:15,467:INFO:Uploading model into container now
2023-12-17 22:33:15,467:INFO:_master_model_container: 15
2023-12-17 22:33:15,467:INFO:_display_container: 2
2023-12-17 22:33:15,467:INFO:DummyClassifier(constant=None, random_state=8629, strategy='prior')
2023-12-17 22:33:15,467:INFO:create_model() successfully completed......................................
2023-12-17 22:33:15,560:INFO:SubProcess create_model() end ==================================
2023-12-17 22:33:15,560:INFO:Creating metrics dataframe
2023-12-17 22:33:15,587:INFO:Initializing create_model()
2023-12-17 22:33:15,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8629, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:15,587:INFO:Checking exceptions
2023-12-17 22:33:15,589:INFO:Importing libraries
2023-12-17 22:33:15,590:INFO:Copying training dataset
2023-12-17 22:33:15,593:INFO:Defining folds
2023-12-17 22:33:15,593:INFO:Declaring metric variables
2023-12-17 22:33:15,593:INFO:Importing untrained model
2023-12-17 22:33:15,593:INFO:Declaring custom model
2023-12-17 22:33:15,594:INFO:Gradient Boosting Classifier Imported successfully
2023-12-17 22:33:15,595:INFO:Cross validation set to False
2023-12-17 22:33:15,595:INFO:Fitting Model
2023-12-17 22:33:16,760:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8629, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-12-17 22:33:16,760:INFO:create_model() successfully completed......................................
2023-12-17 22:33:16,873:INFO:Initializing create_model()
2023-12-17 22:33:16,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:16,874:INFO:Checking exceptions
2023-12-17 22:33:16,876:INFO:Importing libraries
2023-12-17 22:33:16,876:INFO:Copying training dataset
2023-12-17 22:33:16,880:INFO:Defining folds
2023-12-17 22:33:16,880:INFO:Declaring metric variables
2023-12-17 22:33:16,880:INFO:Importing untrained model
2023-12-17 22:33:16,880:INFO:Declaring custom model
2023-12-17 22:33:16,881:INFO:Extreme Gradient Boosting Imported successfully
2023-12-17 22:33:16,882:INFO:Cross validation set to False
2023-12-17 22:33:16,882:INFO:Fitting Model
2023-12-17 22:33:17,055:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='multi:softprob', predictor=None, ...)
2023-12-17 22:33:17,055:INFO:create_model() successfully completed......................................
2023-12-17 22:33:17,175:INFO:Initializing create_model()
2023-12-17 22:33:17,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8629, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:17,175:INFO:Checking exceptions
2023-12-17 22:33:17,178:INFO:Importing libraries
2023-12-17 22:33:17,178:INFO:Copying training dataset
2023-12-17 22:33:17,184:INFO:Defining folds
2023-12-17 22:33:17,184:INFO:Declaring metric variables
2023-12-17 22:33:17,184:INFO:Importing untrained model
2023-12-17 22:33:17,184:INFO:Declaring custom model
2023-12-17 22:33:17,185:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-17 22:33:17,185:INFO:Cross validation set to False
2023-12-17 22:33:17,185:INFO:Fitting Model
2023-12-17 22:33:17,202:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2023-12-17 22:33:17,202:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-17 22:33:17,202:INFO:[LightGBM] [Info] Total Bins 568
2023-12-17 22:33:17,203:INFO:[LightGBM] [Info] Number of data points in the train set: 2083, number of used features: 9
2023-12-17 22:33:17,204:INFO:[LightGBM] [Info] Start training from score -2.280272
2023-12-17 22:33:17,204:INFO:[LightGBM] [Info] Start training from score -0.578516
2023-12-17 22:33:17,204:INFO:[LightGBM] [Info] Start training from score -2.225464
2023-12-17 22:33:17,204:INFO:[LightGBM] [Info] Start training from score -1.474048
2023-12-17 22:33:17,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-17 22:33:17,510:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8629, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-17 22:33:17,510:INFO:create_model() successfully completed......................................
2023-12-17 22:33:17,629:INFO:Initializing create_model()
2023-12-17 22:33:17,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8629, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:17,630:INFO:Checking exceptions
2023-12-17 22:33:17,632:INFO:Importing libraries
2023-12-17 22:33:17,633:INFO:Copying training dataset
2023-12-17 22:33:17,637:INFO:Defining folds
2023-12-17 22:33:17,637:INFO:Declaring metric variables
2023-12-17 22:33:17,637:INFO:Importing untrained model
2023-12-17 22:33:17,637:INFO:Declaring custom model
2023-12-17 22:33:17,638:INFO:Decision Tree Classifier Imported successfully
2023-12-17 22:33:17,639:INFO:Cross validation set to False
2023-12-17 22:33:17,639:INFO:Fitting Model
2023-12-17 22:33:17,650:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8629, splitter='best')
2023-12-17 22:33:17,650:INFO:create_model() successfully completed......................................
2023-12-17 22:33:17,743:INFO:Initializing create_model()
2023-12-17 22:33:17,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8629, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-17 22:33:17,743:INFO:Checking exceptions
2023-12-17 22:33:17,746:INFO:Importing libraries
2023-12-17 22:33:17,747:INFO:Copying training dataset
2023-12-17 22:33:17,751:INFO:Defining folds
2023-12-17 22:33:17,751:INFO:Declaring metric variables
2023-12-17 22:33:17,752:INFO:Importing untrained model
2023-12-17 22:33:17,752:INFO:Declaring custom model
2023-12-17 22:33:17,752:INFO:Random Forest Classifier Imported successfully
2023-12-17 22:33:17,753:INFO:Cross validation set to False
2023-12-17 22:33:17,753:INFO:Fitting Model
2023-12-17 22:33:17,912:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8629, verbose=0, warm_start=False)
2023-12-17 22:33:17,912:INFO:create_model() successfully completed......................................
2023-12-17 22:33:18,040:INFO:_master_model_container: 15
2023-12-17 22:33:18,040:INFO:_display_container: 2
2023-12-17 22:33:18,043:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8629, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='multi:softprob', predictor=None, ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8629, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8629, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8629, verbose=0, warm_start=False)]
2023-12-17 22:33:18,043:INFO:compare_models() successfully completed......................................
2023-12-17 22:33:18,153:INFO:Initializing evaluate_model()
2023-12-17 22:33:18,153:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8629, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-12-17 22:33:18,181:INFO:Initializing plot_model()
2023-12-17 22:33:18,181:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8629, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, system=True)
2023-12-17 22:33:18,182:INFO:Checking exceptions
2023-12-17 22:33:18,186:INFO:Preloading libraries
2023-12-17 22:33:18,187:INFO:Copying training dataset
2023-12-17 22:33:18,187:INFO:Plot type: pipeline
2023-12-17 22:33:18,371:INFO:Visual Rendered Successfully
2023-12-17 22:33:18,477:INFO:plot_model() successfully completed......................................
2023-12-17 22:45:23,030:INFO:Initializing plot_model()
2023-12-17 22:45:23,031:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8629, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, system=True)
2023-12-17 22:45:23,031:INFO:Checking exceptions
2023-12-17 22:45:23,036:INFO:Preloading libraries
2023-12-17 22:45:23,036:INFO:Copying training dataset
2023-12-17 22:45:23,037:INFO:Plot type: parameter
2023-12-17 22:45:23,040:INFO:Visual Rendered Successfully
2023-12-17 22:45:23,149:INFO:plot_model() successfully completed......................................
2023-12-17 22:45:35,787:INFO:Initializing plot_model()
2023-12-17 22:45:35,788:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8629, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC288E21A0>, system=True)
2023-12-17 22:45:35,788:INFO:Checking exceptions
2023-12-17 22:45:35,791:INFO:Preloading libraries
2023-12-17 22:45:35,791:INFO:Copying training dataset
2023-12-17 22:45:35,791:INFO:Plot type: pipeline
2023-12-17 22:45:35,867:INFO:Visual Rendered Successfully
2023-12-17 22:45:35,945:INFO:plot_model() successfully completed......................................
